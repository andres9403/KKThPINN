{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import main\n",
    "from utils import LoadData, LoadModel, load_data\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import tempfile\n",
    "from tabulate import tabulate \n",
    "\n",
    "import pandas as pd\n",
    "# pyomo for optimization\n",
    "import pyomo.environ as pyo\n",
    "\n",
    "# pytorch for training neural network\n",
    "import torch.onnx\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# omlt for interfacing our neural network with pyomo\n",
    "import onnx\n",
    "from omlt import OffsetScaling, OmltBlock\n",
    "from omlt.io.onnx import (\n",
    "    load_onnx_neural_network_with_bounds,\n",
    "    write_onnx_model_with_bounds,\n",
    "    load_onnx_neural_network,\n",
    ")\n",
    "from omlt.neuralnet import (FullSpaceNNFormulation, \n",
    "    ReluComplementarityFormulation, \n",
    "    ReluPartitionFormulation,\n",
    "    ReducedSpaceNNFormulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_arguments(model,model_id,system,scenario):    \n",
    "    if system == 'membrane':\n",
    "        args = argparse.Namespace(\n",
    "            input_dim=7,\n",
    "            hidden_dim=32,\n",
    "            hidden_num=2,\n",
    "            z0_dim=8,\n",
    "            optimizer='adam',\n",
    "            epochs=1000,\n",
    "            batch_size=16,\n",
    "            lr=1e-4,\n",
    "            mu=1,\n",
    "            max_subiter=500,\n",
    "            eta=0.8,\n",
    "            sigma=2,\n",
    "            mu_safe=1e+9,\n",
    "            dtype=32,\n",
    "            dataset_path='/home/andresfel9403/KKThNN/KKThPINN/benchmark_membrane.csv',\n",
    "            val_ratio=0.2,\n",
    "            job='train',\n",
    "            runs=10)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    args.model = model\n",
    "    args.model_id = model_id\n",
    "    args.dataset_type = system\n",
    "    args.scenario = scenario\n",
    "        \n",
    "    \n",
    "    if args.model == 'NN':\n",
    "        args.loss_type = 'MSE'\n",
    "    elif args.model == 'PINN':\n",
    "        args.loss_type = 'PINN'\n",
    "    elif args.model == 'KKThPINN':\n",
    "        args.loss_type = 'MSE'\n",
    "    elif args.model == 'AugLagNN':\n",
    "        args.loss_type = 'MSE'\n",
    "    elif args.model == 'ECNN':\n",
    "        args.loss_type = 'MSE'\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = inputs+outputs\n",
    "\n",
    "df = pd.read_csv(\"benchmark_membrane.csv\", usecols = columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_KKT = add_arguments('KKThPINN','MembraneT_KKThPINN','membrane','demonstration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of A: torch.float32, type of B: torch.float32, type of b: torch.float32\n",
      "train set size: 614, val set size: 204, test set size: 204\n",
      "Start Training...\n",
      "epoch: 00050 loss_train: 0.00554 loss_val: 0.00573 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00100 loss_train: 0.00121 loss_val: 0.00174 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00150 loss_train: 0.00085 loss_val: 0.00139 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00200 loss_train: 0.00071 loss_val: 0.00127 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00250 loss_train: 0.00057 loss_val: 0.00109 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00300 loss_train: 0.00045 loss_val: 0.00092 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00350 loss_train: 0.00038 loss_val: 0.00078 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00400 loss_train: 0.00033 loss_val: 0.00070 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00450 loss_train: 0.00030 loss_val: 0.00065 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00500 loss_train: 0.00027 loss_val: 0.00065 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00550 loss_train: 0.00025 loss_val: 0.00056 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00600 loss_train: 0.00024 loss_val: 0.00054 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00650 loss_train: 0.00022 loss_val: 0.00051 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00700 loss_train: 0.00022 loss_val: 0.00050 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00750 loss_train: 0.00021 loss_val: 0.00047 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00800 loss_train: 0.00020 loss_val: 0.00047 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00850 loss_train: 0.00019 loss_val: 0.00045 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00900 loss_train: 0.00019 loss_val: 0.00044 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00950 loss_train: 0.00018 loss_val: 0.00043 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 01000 loss_train: 0.00018 loss_val: 0.00042 violation_train: 0.00000 violation_val: 0.00000\n",
      "Finished!\n",
      "{'rmse_total': np.float64(0.016087519421119335), 'rmse_unconstrained': np.float64(0.004558618532265707), 'rmse_constrained': np.float64(0.005882742404699017), 'violation': 3.4509562283346895e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andresfel9403/KKThNN/KKThPINN/train.py:264: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(PATH)\n"
     ]
    }
   ],
   "source": [
    "main(args_KKT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the arguments depending on the number of inputs, hidden and output layers, we can train the model selecting the Neural Network model (NN or KKThPINN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of A: torch.float32, type of B: torch.float32, type of b: torch.float32\n",
      "train set size: 614, val set size: 204, test set size: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_221597/2874336590.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(PATH)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, scaling = load_data(args_KKT.dataset_path)\n",
    "inputs = dataset[:,:7]\n",
    "outputs = dataset[:,7:]\n",
    "\n",
    "data = LoadData(args_KKT)\n",
    "model_KKT = LoadModel(args_KKT, data)\n",
    "PATH = '/home/andresfel9403/KKThNN/KKThPINN/models/membrane/KKThPINN/0.2/MembraneT_KKThPINN_0.2_0.pth'\n",
    "checkpoint = torch.load(PATH)\n",
    "model_KKT.load_state_dict(checkpoint['state_dict'])\n",
    "#model_NN.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.46831994e+01 1.04111445e+01 1.42231966e+01 9.99584502e+01\n",
      " 7.26638589e+02 2.69926289e+06 1.76773269e+02]\n"
     ]
    }
   ],
   "source": [
    "x_factor = scaling.scale_[:7]\n",
    "y_factor = scaling.scale_[7:]\n",
    "\n",
    "print(x_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = scaler = OffsetScaling(\n",
    "    offset_inputs={i: 0 for i in range(len(x_factor))},\n",
    "    factor_inputs={i: x_factor[i] for i in range(len(x_factor))},\n",
    "    offset_outputs={i: 0 for i in range(len(y_factor))},\n",
    "    factor_outputs={i: y_factor[i] for i in range(len(y_factor))},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "x_dummy = torch.from_numpy(inputs[0]).float()\n",
    "ub = np.max(inputs, 0)\n",
    "lb = np.min(inputs, 0)\n",
    "\n",
    "scaled_input_bounds = {i: (lb[i], ub[i]) for i in range(len(inputs[0]))}\n",
    "print(ub.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_weights(original_model, modified_model):\n",
    "    with torch.no_grad():\n",
    "        for original_layer, modified_layer in zip(original_model.layers, modified_model.layers):\n",
    "            if isinstance(original_layer, nn.Linear) and isinstance(modified_layer, nn.Linear):\n",
    "                modified_layer.weight.copy_(original_layer.weight)\n",
    "                modified_layer.bias.copy_(original_layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_onnx_model(data,args,model,file_path,x,input_bounds):\n",
    "    args.model='NN'\n",
    "    print('Saving standard model')\n",
    "    modified_model = LoadModel(args,data)\n",
    "    transfer_weights(model,modified_model)\n",
    "    create_onnx_model(data,modified_model,file_path,x,input_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_onnx_model(data,model,file_path,x,input_bounds):\n",
    "    \n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        x,\n",
    "        file_path,\n",
    "        input_names=[\"input\"],\n",
    "        dynamo = False\n",
    "    )\n",
    "    write_onnx_model_with_bounds(file_path, None, input_bounds)\n",
    "    print(f\"Wrote PyTorch Onnx model to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving standard model\n",
      "Wrote PyTorch Onnx model to KKThPINN_Membrane.onnx\n"
     ]
    }
   ],
   "source": [
    "_create_onnx_model(data,args_KKT,model_KKT,'KKThPINN_Membrane.onnx',x_dummy,scaled_input_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_definition_NN = load_onnx_neural_network_with_bounds('KKThPINN_Membrane.onnx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "formulation_NN = FullSpaceNNFormulation(network_definition_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tInputLayer(input_size=[7], output_size=[7])\tlinear\n",
      "1\tDenseLayer(input_size=[7], output_size=[32])\trelu\n",
      "2\tDenseLayer(input_size=[32], output_size=[32])\trelu\n",
      "3\tDenseLayer(input_size=[32], output_size=[8])\tlinear\n"
     ]
    }
   ],
   "source": [
    "for layer_id, layer in enumerate(network_definition_NN.layers):\n",
    "    print(f\"{layer_id}\\t{layer}\\t{layer.activation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[0]' to a numeric value\n",
      "`0` outside the bounds (0.002303625455624813, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[0]' to a numeric value\n",
      "`0` outside the bounds (0.002303625455624813, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[1]' to a numeric value\n",
      "`0` outside the bounds (0.00045880834803283796, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[2]' to a numeric value\n",
      "`0` outside the bounds (0.0022512226291679363, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[3]' to a numeric value\n",
      "`0` outside the bounds (0.10018982303101381, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[4]' to a numeric value\n",
      "`0` outside the bounds (0.25788606628182886, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[5]' to a numeric value\n",
      "`0` outside the bounds (0.4816711270961038, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[6]' to a numeric value\n",
      "`0` outside the bounds (0.056910004685567034, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "0.9869786500930786\n"
     ]
    }
   ],
   "source": [
    "inputs = ['F_MeOH',\n",
    "    'F_DME',\n",
    "    'F_H2O',\n",
    "    'F_N2',\n",
    "    'T_in',\n",
    "    'P_in',\n",
    "    'T_permeate']\n",
    "\n",
    "outputs = [\n",
    "    'F_MeOH_O',\n",
    "    'F_DME_O',\n",
    "    'F_H2O_O',\n",
    "    'F_H2O_M_O',\n",
    "    'F_N2_O',\n",
    "    'T_Out',\n",
    "    'T_Out_M',\n",
    "    'P_Out'\n",
    "]\n",
    "model = pyo.ConcreteModel()\n",
    "\n",
    "# create an OMLT block for the neural network and build its formulation\n",
    "model.membrane= OmltBlock()\n",
    "model.membrane.build_formulation(formulation_NN)\n",
    "model.membrane.inputs[0]\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    model.membrane.inputs[i] = x_dummy[i].item()\n",
    "    model.membrane.inputs[i].setlb(lb[i])\n",
    "    model.membrane.inputs[i].setub(ub[i])\n",
    "\n",
    "for i in range(len(outputs)):\n",
    "    model.membrane.outputs[i] = 0.0\n",
    "    model.membrane.outputs[i].setlb(0.0)\n",
    "\n",
    "\n",
    "# model.sections = pyo.Set(initialize=[\"retentate\", \"permeate\"], doc=\"sections in the model\")\n",
    "# model.components = pyo.Set(initialize=[\"MeOH\", \"DME\", \"H2O\", \"N2\"], doc=\"Components in the model\")\n",
    "\n",
    "print(pyo.value(model.membrane.inputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Implicitly replacing the Component attribute Tin_constr (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute Tm_constr (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute TFlow_constr\n",
      "(type=<class 'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown\n",
      "with a new Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute P_constr (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute MassBal (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute Flow_Nitrog (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute Tout_constr (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute Tout_M_constr\n",
      "(type=<class 'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown\n",
      "with a new Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute Flow_MEOH (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute Flow_DME (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute Flow_H2O (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Tin_idx = inputs.index('T_in')\n",
    "Tm_idx = inputs.index('T_permeate')\n",
    "F_MeOH_idx = inputs.index('F_MeOH')\n",
    "F_DME_idx = inputs.index('F_DME')\n",
    "F_H2O_idx = inputs.index('F_H2O')\n",
    "F_N2_idx = inputs.index('F_N2')\n",
    "P_in_idx = inputs.index('P_in')\n",
    "\n",
    "FMeOh_O_idx = outputs.index('F_MeOH_O')\n",
    "FDME_O_idx = outputs.index('F_DME_O')\n",
    "FH2O_O_idx = outputs.index('F_H2O_O')\n",
    "FH2O_M_O_idx = outputs.index('F_H2O_M_O')\n",
    "FN2_O_idx = outputs.index('F_N2_O')\n",
    "TOut_idx = outputs.index('T_Out')\n",
    "TOut_M_idx = outputs.index('T_Out_M')\n",
    "POut_idx = outputs.index('P_Out')\n",
    "\n",
    "def Tin_bounds(m):\n",
    "    return (460,m.membrane.inputs[Tin_idx]*x_factor[Tin_idx],1000)\n",
    "\n",
    "def Tout_bounds(m):\n",
    "    return (460,y_factor[TOut_idx]*m.membrane.outputs[TOut_idx],1000)\n",
    "\n",
    "def TOut_mem_bounds(m):\n",
    "    return (283.15,y_factor[TOut_M_idx]*m.membrane.outputs[TOut_M_idx],450)\n",
    "\n",
    "def T_mem_bounds(m):\n",
    "    return (283.15,m.membrane.inputs[Tm_idx]*x_factor[Tm_idx],450)\n",
    "\n",
    "def TFlow_bounds(m):\n",
    "    FMeOh = m.membrane.inputs[F_MeOH_idx]*x_factor[F_MeOH_idx]\n",
    "    FDME = m.membrane.inputs[F_DME_idx]*x_factor[F_DME_idx]\n",
    "    FH2O = m.membrane.inputs[F_H2O_idx]*x_factor[F_H2O_idx]\n",
    "    FN2 = m.membrane.inputs[F_N2_idx]*x_factor[F_N2_idx]\n",
    "    Ftot = FMeOh + FDME + FH2O + FN2\n",
    "    return (1, Ftot, 100)\n",
    "\n",
    "\n",
    "def P_bounds(m):\n",
    "    return (13e5, m.membrane.inputs[P_in_idx]*x_factor[P_in_idx], 27e5)\n",
    "\n",
    "def POut_bounds(m):\n",
    "    return (13e5, m.membrane.outputs[POut_idx]*y_factor[POut_idx], 27e5)\n",
    "\n",
    "def Mas_Bal(m):\n",
    "    FMeOh = m.membrane.inputs[F_MeOH_idx]*x_factor[F_MeOH_idx]\n",
    "    FDME = m.membrane.inputs[F_DME_idx]*x_factor[F_DME_idx]\n",
    "    FH2O = m.membrane.inputs[F_H2O_idx]*x_factor[F_H2O_idx]\n",
    "    FN2 = m.membrane.inputs[F_N2_idx]*x_factor[F_N2_idx]\n",
    "    FMeOh_O = m.membrane.outputs[FMeOh_O_idx]*y_factor[FMeOh_O_idx]\n",
    "    FDME_O = m.membrane.outputs[FDME_O_idx]*y_factor[FDME_O_idx]\n",
    "    FH2O_O = m.membrane.outputs[FH2O_O_idx]*y_factor[FH2O_O_idx]\n",
    "    FN2_O = m.membrane.outputs[FN2_O_idx]*y_factor[FN2_O_idx]\n",
    "    FH2O_M_O = m.membrane.outputs[FH2O_M_O_idx]*y_factor[FH2O_M_O_idx]\n",
    "\n",
    "    In = FMeOh + FDME + FH2O + FN2\n",
    "    Out = FMeOh_O + FDME_O + FH2O_O + FN2_O + FH2O_M_O\n",
    "    MassBal = abs(In - Out)\n",
    "    return (0, MassBal, 1e-6)\n",
    "\n",
    "def Flow_Nitrog(m):\n",
    "    FN2 = m.membrane.inputs[F_N2_idx]*x_factor[F_N2_idx]\n",
    "    FN2_O = m.membrane.outputs[FN2_O_idx]*y_factor[FN2_O_idx]\n",
    "    \n",
    "    return (FN2-FN2_O == 0)\n",
    "\n",
    "def Flow_MEOH(m):\n",
    "    return m.membrane.inputs[F_MeOH_idx]*x_factor[F_MeOH_idx] == 0.93*15.58 \n",
    "\n",
    "def Flow_DME(m):\n",
    "    return m.membrane.inputs[F_DME_idx]*x_factor[F_DME_idx] == 0.06*15.58\n",
    "\n",
    "def Flow_H2O(m):\n",
    "    return m.membrane.inputs[F_H2O_idx]*x_factor[F_H2O_idx] == 0.01*15.58\n",
    "\n",
    "\n",
    "\n",
    "model.Tin_constr = pyo.Constraint(rule = Tin_bounds)\n",
    "model.Tm_constr = pyo.Constraint(rule = T_mem_bounds)\n",
    "model.TFlow_constr = pyo.Constraint(rule = TFlow_bounds)\n",
    "model.P_constr = pyo.Constraint(rule = P_bounds)\n",
    "model.MassBal = pyo.Constraint(rule = Mas_Bal)\n",
    "model.Flow_Nitrog = pyo.Constraint(rule = Flow_Nitrog)\n",
    "model.Tout_constr = pyo.Constraint(rule = Tout_bounds)\n",
    "model.Tout_M_constr = pyo.Constraint(rule = TOut_mem_bounds)\n",
    "\n",
    "model.Flow_MEOH = pyo.Constraint(rule = Flow_MEOH)\n",
    "model.Flow_DME = pyo.Constraint(rule = Flow_DME)\n",
    "model.Flow_H2O = pyo.Constraint(rule = Flow_H2O)\n",
    "\n",
    "model.POut_constr = pyo.Constraint(rule = POut_bounds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Implicitly replacing the Component attribute objective (type=<class\n",
      "'pyomo.core.base.objective.ScalarObjective'>) on block unknown with a new\n",
      "Component (type=<class 'pyomo.core.base.objective.ScalarObjective'>). This is\n",
      "usually indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n"
     ]
    }
   ],
   "source": [
    "def objective_rule(m):\n",
    "    prices = {\n",
    "        \"MeOH\": 891*1e-6,  # Cost of Methanol in $/kg\n",
    "        \"DME\": 2021.84*1e-6,   # Cost of Dimethyl Ether in $/kg\n",
    "        \"H2O\": 0.29*1e-6,  # Cost of Water in $/kg\n",
    "        \"N2\": 121.254*1e-6  # Cost of Nitrogen in $/kg\n",
    "    }\n",
    "\n",
    "    MW = {\n",
    "        \"MeOH\": 32.04,  # MW of Methanol in g/mol\n",
    "        \"DME\": 46.069,   # Cost of Dimethyl Ether in $/kg\n",
    "        \"H2O\": 18.0152,  # Cost of Water in $/kg\n",
    "        \"N2\": 28.0134  # Cost of Nitrogen in $/kg\n",
    "    }\n",
    "\n",
    "    DME_O = m.membrane.outputs[outputs.index(\"F_DME_O\")]*y_factor[outputs.index(\"F_DME_O\")]\n",
    "    H2O_O = m.membrane.outputs[outputs.index(\"F_H2O_O\")]*y_factor[outputs.index(\"F_H2O_O\")]\n",
    "    H2O_M_O = m.membrane.outputs[outputs.index(\"F_H2O_M_O\")]*y_factor[outputs.index(\"F_H2O_M_O\")]\n",
    "    MeOH_In = m.membrane.inputs[inputs.index(\"F_MeOH\")]*x_factor[inputs.index(\"F_MeOH\")]\n",
    "    N2_In = m.membrane.inputs[inputs.index(\"F_N2\")]*x_factor[inputs.index(\"F_N2\")]\n",
    "    DME_In = m.membrane.inputs[inputs.index(\"F_DME\")]*x_factor[inputs.index(\"F_DME\")]\n",
    "\n",
    "    product_profit = prices[\"DME\"]*DME_O * MW[\"DME\"] + prices[\"H2O\"]*(H2O_O + H2O_M_O) * MW[\"H2O\"]\n",
    "\n",
    "    feedstock_cost = prices[\"MeOH\"]*MeOH_In * MW[\"MeOH\"] + prices[\"N2\"]*N2_In * MW[\"N2\"] + prices[\"DME\"]*DME_O * MW[\"DME\"]\n",
    "    return product_profit - feedstock_cost\n",
    "\n",
    "model.objective = pyo.Objective(rule = objective_rule, sense = pyo.maximize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipopt 3.14.6: \n",
      "==> Warning: Treating 64 binary and 0 integer variables as continuous.\n",
      "\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.14.6, running with linear solver MUMPS 5.2.1.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:     1593\n",
      "Number of nonzeros in inequality constraint Jacobian.:      523\n",
      "Number of nonzeros in Lagrangian Hessian.............:       45\n",
      "\n",
      "Total number of variables............................:      243\n",
      "                     variables with only lower bounds:        8\n",
      "                variables with lower and upper bounds:      227\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:      114\n",
      "Total number of inequality constraints...............:      264\n",
      "        inequality constraints with only lower bounds:       64\n",
      "   inequality constraints with lower and upper bounds:        8\n",
      "        inequality constraints with only upper bounds:      192\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  4.5066896e-01 3.30e+05 8.09e-01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  4.5066879e-01 3.30e+05 2.85e+01  -1.0 4.79e+00    -  3.82e-01 1.02e-05h  1\n",
      "   2  4.5031843e-01 3.22e+05 5.37e+02  -1.0 2.24e+01    -  4.48e-01 2.35e-02f  1\n",
      "   3  4.5027216e-01 3.20e+05 3.66e+04  -1.0 5.93e+01    -  4.50e-01 6.93e-03h  1\n",
      "   4  4.5027159e-01 3.20e+05 1.59e+08  -1.0 5.94e+01    -  5.27e-01 1.22e-04h  1\n",
      "   5r 4.5027159e-01 3.20e+05 1.00e+03   1.8 0.00e+00    -  0.00e+00 3.06e-07R  3\n",
      "   6r 4.5026819e-01 3.19e+05 1.20e+03   1.8 2.47e+03    -  2.07e-03 1.76e-05f  1\n",
      "   7r 4.4981446e-01 1.06e+02 1.04e+03   1.1 1.78e+03    -  5.41e-03 6.95e-03f  1\n",
      "   8r 4.4975891e-01 1.06e+02 7.78e+03   1.1 6.18e+01    -  8.18e-02 1.31e-02f  1\n",
      "   9r 4.5068387e-01 1.06e+02 1.40e+04   1.1 3.86e+01    -  2.26e-01 1.45e-01f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10r 4.5351541e-01 1.06e+02 2.86e+04   1.1 1.77e+01    -  6.99e-01 4.08e-01f  1\n",
      "  11r 4.5782779e-01 1.06e+02 1.12e+04   1.1 2.33e+00    -  4.49e-01 5.42e-01f  1\n",
      "  12r 4.4946989e-01 1.06e+02 2.18e+03   0.4 5.66e+00    -  9.73e-01 8.90e-01f  1\n",
      "  13r 4.4987802e-01 1.06e+02 3.35e+02   0.4 3.34e+00    -  1.00e+00 1.00e+00f  1\n",
      "  14r 4.4814486e-01 1.06e+02 5.59e+01  -0.3 2.39e+00    -  7.30e-01 8.47e-01f  1\n",
      "  15r 4.4774968e-01 1.06e+02 4.82e+02  -1.0 2.18e+00    -  6.22e-01 8.50e-01f  1\n",
      "  16r 4.4770144e-01 1.06e+02 3.61e+01  -1.0 6.32e-01    -  8.15e-01 9.24e-01f  1\n",
      "  17r 4.4769808e-01 1.06e+02 9.63e-07  -1.0 8.86e-02    -  1.00e+00 1.00e+00f  1\n",
      "  18r 4.4763984e-01 1.06e+02 3.79e+00  -3.9 2.44e-01    -  5.41e-01 7.30e-01f  1\n",
      "  19r 4.4762414e-01 1.06e+02 5.19e-01  -3.9 7.52e-02    -  8.31e-01 8.00e-01f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  20r 4.4762095e-01 1.06e+02 2.25e-01  -3.9 5.37e-02    -  9.50e-01 9.31e-01f  1\n",
      "  21r 4.4762078e-01 1.06e+02 1.38e-09  -3.9 2.97e-01    -  1.00e+00 1.00e+00f  1\n",
      "  22r 4.4762068e-01 1.06e+02 1.60e+00  -5.8 2.44e-01    -  7.92e-01 9.90e-01f  1\n",
      "  23r 4.4762068e-01 1.06e+02 5.42e+01  -5.8 2.38e-02    -  9.28e-01 1.00e+00f  1\n",
      "  24r 4.4762068e-01 1.06e+02 2.23e+02  -5.8 7.49e-02    -  1.00e+00 7.35e-02f  2\n",
      "  25r 4.4762068e-01 1.06e+02 1.64e-11  -5.8 1.07e-01    -  1.00e+00 1.00e+00f  1\n",
      "  26r 4.4762068e-01 1.06e+02 1.63e+01  -8.7 5.71e-02    -  8.67e-01 7.88e-01f  1\n",
      "  27r 4.4762068e-01 1.06e+02 8.20e+00  -8.7 5.44e-03    -  8.29e-01 9.79e-01f  1\n",
      "\n",
      "Number of Iterations....: 27\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   4.4762067760134583e-01    4.4762067760134583e-01\n",
      "Dual infeasibility......:   4.1917069166133802e-01    4.1917069166133802e-01\n",
      "Constraint violation....:   6.0176930303473554e+01    1.0637672670077102e+02\n",
      "Variable bound violation:   9.9999790670324273e-09    9.9999790670324273e-09\n",
      "Complementarity.........:   2.1965690262554386e-08    2.1965690262554386e-08\n",
      "Overall NLP error.......:   6.0176930303473554e+01    1.0637672670077102e+02\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 33\n",
      "Number of objective gradient evaluations             = 7\n",
      "Number of equality constraint evaluations            = 33\n",
      "Number of inequality constraint evaluations          = 33\n",
      "Number of equality constraint Jacobian evaluations   = 30\n",
      "Number of inequality constraint Jacobian evaluations = 30\n",
      "Number of Lagrangian Hessian evaluations             = 28\n",
      "Total seconds in IPOPT                               = 0.087\n",
      "\n",
      "EXIT: Converged to a point of local infeasibility. Problem may be infeasible.\n",
      "WARNING: Loading a SolverResults object with a warning status into\n",
      "model.name=\"unknown\";\n",
      "    - termination condition: infeasible\n",
      "    - message from solver: Ipopt 3.14.6\\x3a Converged to a locally infeasible\n",
      "      point. Problem may be infeasible.\n"
     ]
    }
   ],
   "source": [
    "solver = pyo.SolverFactory(\"ipopt\")\n",
    "status = solver.solve(model, tee=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+---------+\n",
      "| Input Parameter   | Value              | Output Parameter   | Value   |\n",
      "+===================+====================+====================+=========+\n",
      "| F_MeOH            | 14.489399999999964 | F_MeOH_O           | 1.38592 |\n",
      "+-------------------+--------------------+--------------------+---------+\n",
      "| F_DME             | 0.9347999999999843 | F_DME_O            | 7.45652 |\n",
      "+-------------------+--------------------+--------------------+---------+\n",
      "| F_H2O             | 0.1557999999999662 | F_H2O_O            | 2.27992 |\n",
      "+-------------------+--------------------+--------------------+---------+\n",
      "| -                 | -                  | F_H2O_M_O          | 4.45764 |\n",
      "+-------------------+--------------------+--------------------+---------+\n",
      "| F_N2              | 10.014818440879939 | F_N2_O             | 10.0148 |\n",
      "+-------------------+--------------------+--------------------+---------+\n",
      "| T_in              | 459.99999541206734 | T_Out              | 1000    |\n",
      "+-------------------+--------------------+--------------------+---------+\n",
      "| P_in              | 1300156.9731093566 | P_Out              | 2.7e+06 |\n",
      "+-------------------+--------------------+--------------------+---------+\n",
      "| T_In_M            | 176.77327046772896 | T_Out_M            | 283.15  |\n",
      "+-------------------+--------------------+--------------------+---------+\n",
      "+-----------------+---------+\n",
      "| MeOH Conversion | 0.90435 |\n",
      "+-----------------+---------+\n",
      "Mass Balance Violation: 1.009618660674505e-06\n"
     ]
    }
   ],
   "source": [
    "F_MEOH_IN = pyo.value(model.membrane.inputs[inputs.index(\"F_MeOH\")])*x_factor[inputs.index(\"F_MeOH\")]\n",
    "F_MEOH_OUT = pyo.value(model.membrane.outputs[outputs.index(\"F_MeOH_O\")])*y_factor[outputs.index(\"F_MeOH_O\")]\n",
    "\n",
    "F_DEM_IN = pyo.value(model.membrane.inputs[inputs.index(\"F_DME\")])*x_factor[inputs.index(\"F_DME\")]\n",
    "F_DME_OUT = pyo.value(model.membrane.outputs[outputs.index(\"F_DME_O\")])*y_factor[outputs.index(\"F_DME_O\")]\n",
    "\n",
    "F_H2O_IN = pyo.value(model.membrane.inputs[inputs.index(\"F_H2O\")])*x_factor[inputs.index(\"F_H2O\")]\n",
    "F_H2O_OUT = pyo.value(model.membrane.outputs[outputs.index(\"F_H2O_O\")])*y_factor[outputs.index(\"F_H2O_O\")]\n",
    "F_H2O_M_OUT = pyo.value(model.membrane.outputs[outputs.index(\"F_H2O_M_O\")])*y_factor[outputs.index(\"F_H2O_M_O\")]\n",
    "\n",
    "F_N2_IN = pyo.value(model.membrane.inputs[inputs.index(\"F_N2\")])*x_factor[inputs.index(\"F_N2\")]\n",
    "F_N2_OUT = pyo.value(model.membrane.outputs[outputs.index(\"F_N2_O\")])*y_factor[outputs.index(\"F_N2_O\")]\n",
    "\n",
    "T_IN = pyo.value(model.membrane.inputs[inputs.index(\"T_in\")])*x_factor[inputs.index(\"T_in\")]\n",
    "T_M_IN = pyo.value(model.membrane.inputs[inputs.index(\"T_permeate\")])*x_factor[inputs.index(\"T_permeate\")]\n",
    "T_OUT = pyo.value(model.membrane.outputs[outputs.index(\"T_Out\")])*y_factor[outputs.index(\"T_Out\")]\n",
    "T_M_OUT = pyo.value(model.membrane.outputs[outputs.index(\"T_Out_M\")])*y_factor[outputs.index(\"T_Out_M\")]\n",
    "\n",
    "P_IN = pyo.value(model.membrane.inputs[inputs.index(\"P_in\")])*x_factor[inputs.index(\"P_in\")]\n",
    "P_OUT = pyo.value(model.membrane.outputs[outputs.index(\"P_Out\")])*y_factor[outputs.index(\"P_Out\")]\n",
    "\n",
    "CONVERSION = (F_MEOH_IN - F_MEOH_OUT)/F_MEOH_IN\n",
    "Mas_Bal = pyo.value(model.MassBal)\n",
    "\n",
    "data_tabulate = [\n",
    "    [\"Input Parameter\",\"Value\",\"Output Parameter\",\"Value\"],\n",
    "    [\"F_MeOH\", F_MEOH_IN, \"F_MeOH_O\", F_MEOH_OUT],\n",
    "    [\"F_DME\", F_DEM_IN, \"F_DME_O\", F_DME_OUT],\n",
    "    [\"F_H2O\", F_H2O_IN, \"F_H2O_O\", F_H2O_OUT],\n",
    "    [\"-\", \"-\", \"F_H2O_M_O\", F_H2O_M_OUT],\n",
    "    [\"F_N2\", F_N2_IN, \"F_N2_O\", F_N2_OUT],\n",
    "    [\"T_in\", T_IN, \"T_Out\", T_OUT],\n",
    "    [\"P_in\", P_IN, \"P_Out\", P_OUT],\n",
    "    [\"T_In_M\", T_M_IN, \"T_Out_M\", T_M_OUT],\n",
    "]\n",
    "\n",
    "conversion_table = [\n",
    "    [\"MeOH Conversion\", CONVERSION]\n",
    "]\n",
    "\n",
    "print(tabulate(data_tabulate, headers=\"firstrow\", tablefmt=\"grid\", colalign=(\"left\", \"left\", \"left\", \"left\")))\n",
    "print(tabulate(conversion_table, tablefmt=\"grid\", colalign=(\"left\", \"left\")))\n",
    "print(f\"Mass Balance Violation: {Mas_Bal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.46831994e+01 1.04111445e+01 1.42231966e+01 9.99584502e+01\n",
      " 7.26638589e+02 2.69926289e+06 1.76773269e+02]\n"
     ]
    }
   ],
   "source": [
    "print(x_factor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemfigmkr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
