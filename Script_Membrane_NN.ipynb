{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import main\n",
    "from utils import LoadData, LoadModel, load_data\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import tempfile\n",
    "from tabulate import tabulate \n",
    "import pandas as pd\n",
    "# pyomo for optimization\n",
    "import pyomo.environ as pyo\n",
    "\n",
    "# pytorch for training neural network\n",
    "import torch.onnx\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# omlt for interfacing our neural network with pyomo\n",
    "import onnx\n",
    "from omlt import OffsetScaling, OmltBlock\n",
    "from omlt.io.onnx import (\n",
    "    load_onnx_neural_network_with_bounds,\n",
    "    write_onnx_model_with_bounds,\n",
    "    load_onnx_neural_network,\n",
    ")\n",
    "from omlt.neuralnet import (FullSpaceNNFormulation, \n",
    "    ReluComplementarityFormulation, \n",
    "    ReluPartitionFormulation,\n",
    "    ReducedSpaceNNFormulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_arguments(model,model_id,system,scenario):    \n",
    "    if system == 'membrane':\n",
    "        args = argparse.Namespace(\n",
    "            input_dim=7,\n",
    "            hidden_dim=32,\n",
    "            hidden_num=2,\n",
    "            z0_dim=8,\n",
    "            optimizer='adam',\n",
    "            epochs=1000,\n",
    "            batch_size=16,\n",
    "            lr=1e-4,\n",
    "            mu=1,\n",
    "            max_subiter=500,\n",
    "            eta=0.8,\n",
    "            sigma=2,\n",
    "            mu_safe=1e+9,\n",
    "            dtype=32,\n",
    "            dataset_path='/home/andresfel9403/KKThNN/KKThPINN/benchmark_membrane.csv',\n",
    "            val_ratio=0.2,\n",
    "            job='train',\n",
    "            runs=10)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    args.model = model\n",
    "    args.model_id = model_id\n",
    "    args.dataset_type = system\n",
    "    args.scenario = scenario\n",
    "        \n",
    "    \n",
    "    if args.model == 'NN':\n",
    "        args.loss_type = 'MSE'\n",
    "    elif args.model == 'PINN':\n",
    "        args.loss_type = 'PINN'\n",
    "    elif args.model == 'KKThPINN':\n",
    "        args.loss_type = 'MSE'\n",
    "    elif args.model == 'AugLagNN':\n",
    "        args.loss_type = 'MSE'\n",
    "    elif args.model == 'ECNN':\n",
    "        args.loss_type = 'MSE'\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Usecols do not match columns, columns expected but not found: ['F_MeOH_O', 'F_H2O_M_O', 'F_H2O', 'P_in', 'F_MeOH', 'T_permeate', 'F_N2_O', 'T_Out_M', 'F_DME', 'F_N2', 'F_DME_O', 'T_Out', 'F_H2O_O', 'P_Out', 'T_in']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m columns \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m+\u001b[39moutputs\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbenchmark_membrane.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/chemfigmkr/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/chemfigmkr/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/chemfigmkr/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/chemfigmkr/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/chemfigmkr/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:140\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mset\u001b[39m(usecols)\u001b[38;5;241m.\u001b[39missubset(\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_names\n\u001b[1;32m    139\u001b[0m ):\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_usecols_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morig_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(usecols):  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/chemfigmkr/lib/python3.12/site-packages/pandas/io/parsers/base_parser.py:979\u001b[0m, in \u001b[0;36mParserBase._validate_usecols_names\u001b[0;34m(self, usecols, names)\u001b[0m\n\u001b[1;32m    977\u001b[0m missing \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m usecols \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m names]\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 979\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsecols do not match columns, columns expected but not found: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    981\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    982\u001b[0m     )\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m usecols\n",
      "\u001b[0;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['F_MeOH_O', 'F_H2O_M_O', 'F_H2O', 'P_in', 'F_MeOH', 'T_permeate', 'F_N2_O', 'T_Out_M', 'F_DME', 'F_N2', 'F_DME_O', 'T_Out', 'F_H2O_O', 'P_Out', 'T_in']"
     ]
    }
   ],
   "source": [
    "columns = inputs+outputs\n",
    "\n",
    "df = pd.read_csv(\"benchmark_membrane.csv\", usecols = columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_NN = add_arguments('NN','MembraneT_NN','membrane','demonstration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of A: torch.float32, type of B: torch.float32, type of b: torch.float32\n",
      "train set size: 614, val set size: 204, test set size: 204\n",
      "Start Training...\n",
      "epoch: 00050 loss_train: 0.01600 loss_val: 0.01663 violation_train: 12.89502 violation_val: 13.13791\n",
      "epoch: 00100 loss_train: 0.00403 loss_val: 0.00412 violation_train: 2.12080 violation_val: 2.26296\n",
      "epoch: 00150 loss_train: 0.00114 loss_val: 0.00154 violation_train: 0.44635 violation_val: 0.46832\n",
      "epoch: 00200 loss_train: 0.00094 loss_val: 0.00131 violation_train: 0.42455 violation_val: 0.50284\n",
      "epoch: 00250 loss_train: 0.00087 loss_val: 0.00123 violation_train: 0.47292 violation_val: 0.50085\n",
      "epoch: 00300 loss_train: 0.00079 loss_val: 0.00111 violation_train: 0.43416 violation_val: 0.41581\n",
      "epoch: 00350 loss_train: 0.00074 loss_val: 0.00103 violation_train: 0.33364 violation_val: 0.34516\n",
      "epoch: 00400 loss_train: 0.00070 loss_val: 0.00100 violation_train: 0.28506 violation_val: 0.32665\n",
      "epoch: 00450 loss_train: 0.00067 loss_val: 0.00098 violation_train: 0.27336 violation_val: 0.35786\n",
      "epoch: 00500 loss_train: 0.00065 loss_val: 0.00097 violation_train: 0.25882 violation_val: 0.32448\n",
      "epoch: 00550 loss_train: 0.00066 loss_val: 0.00097 violation_train: 0.24302 violation_val: 0.26811\n",
      "epoch: 00600 loss_train: 0.00063 loss_val: 0.00096 violation_train: 0.22970 violation_val: 0.26319\n",
      "epoch: 00650 loss_train: 0.00063 loss_val: 0.00096 violation_train: 0.21602 violation_val: 0.25669\n",
      "epoch: 00700 loss_train: 0.00062 loss_val: 0.00097 violation_train: 0.23567 violation_val: 0.24397\n",
      "epoch: 00750 loss_train: 0.00060 loss_val: 0.00093 violation_train: 0.21455 violation_val: 0.32803\n",
      "epoch: 00800 loss_train: 0.00058 loss_val: 0.00090 violation_train: 0.21224 violation_val: 0.28063\n",
      "epoch: 00850 loss_train: 0.00054 loss_val: 0.00089 violation_train: 0.21109 violation_val: 0.28013\n",
      "epoch: 00900 loss_train: 0.00052 loss_val: 0.00084 violation_train: 0.17306 violation_val: 0.20155\n",
      "epoch: 00950 loss_train: 0.00049 loss_val: 0.00083 violation_train: 0.17046 violation_val: 0.18684\n",
      "epoch: 01000 loss_train: 0.00047 loss_val: 0.00079 violation_train: 0.15690 violation_val: 0.17547\n",
      "Finished!\n",
      "{'rmse_total': np.float64(0.02336117749666911), 'rmse_unconstrained': np.float64(0.004854031894047515), 'rmse_constrained': np.float64(0.007394539849255121), 'violation': 0.13215896487236023, 'post_rmse_total': np.float64(0.02334884435707298), 'post_rmse_unconstrained': np.float64(0.005797210773185577), 'post_rmse_constrained': np.float64(0.006891309089263516)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andresfel9403/KKThNN/KKThPINN/train.py:264: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(PATH)\n"
     ]
    }
   ],
   "source": [
    "main(args_NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the arguments depending on the number of inputs, hidden and output layers, we can train the model selecting the Neural Network model (NN or KKThPINN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of A: torch.float32, type of B: torch.float32, type of b: torch.float32\n",
      "train set size: 614, val set size: 204, test set size: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_432290/1828051342.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(PATH)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, scaling = load_data(args_NN.dataset_path)\n",
    "inputs = dataset[:,:7]\n",
    "outputs = dataset[:,7:]\n",
    "\n",
    "data = LoadData(args_NN)\n",
    "model_NN = LoadModel(args_NN, data)\n",
    "PATH = '/home/andresfel9403/KKThNN/KKThPINN/models/membrane/NN/0.2/MembraneT_NN_0.2_0.pth'\n",
    "checkpoint = torch.load(PATH)\n",
    "model_NN.load_state_dict(checkpoint['state_dict'])\n",
    "#model_NN.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.46831994e+01 1.04111445e+01 1.42231966e+01 9.99584502e+01\n",
      " 7.26638589e+02 2.69926289e+06 1.76773269e+02]\n"
     ]
    }
   ],
   "source": [
    "x_factor = scaling.scale_[:7]\n",
    "y_factor = scaling.scale_[7:]\n",
    "\n",
    "print(x_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = scaler = OffsetScaling(\n",
    "    offset_inputs={i: 0 for i in range(len(x_factor))},\n",
    "    factor_inputs={i: x_factor[i] for i in range(len(x_factor))},\n",
    "    offset_outputs={i: 0 for i in range(len(y_factor))},\n",
    "    factor_outputs={i: y_factor[i] for i in range(len(y_factor))},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "x_dummy = torch.from_numpy(inputs[0]).float()\n",
    "ub = np.max(inputs, 0)\n",
    "lb = np.min(inputs, 0)\n",
    "\n",
    "scaled_input_bounds = {i: (lb[i], ub[i]) for i in range(len(inputs[0]))}\n",
    "print(ub.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_weights(original_model, modified_model):\n",
    "    with torch.no_grad():\n",
    "        for original_layer, modified_layer in zip(original_model.layers, modified_model.layers):\n",
    "            if isinstance(original_layer, nn.Linear) and isinstance(modified_layer, nn.Linear):\n",
    "                modified_layer.weight.copy_(original_layer.weight)\n",
    "                modified_layer.bias.copy_(original_layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_onnx_model(data,args,model,file_path,x,input_bounds):\n",
    "    args.model='NN'\n",
    "    print('Saving standard model')\n",
    "    modified_model = LoadModel(args,data)\n",
    "    transfer_weights(model,modified_model)\n",
    "    create_onnx_model(data,modified_model,file_path,x,input_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_onnx_model(data,model,file_path,x,input_bounds):\n",
    "    \n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        x,\n",
    "        file_path,\n",
    "        input_names=[\"input\"],\n",
    "        dynamo = False\n",
    "    )\n",
    "    write_onnx_model_with_bounds(file_path, None, input_bounds)\n",
    "    print(f\"Wrote PyTorch Onnx model to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving standard model\n",
      "Wrote PyTorch Onnx model to NN_Membrane.onnx\n"
     ]
    }
   ],
   "source": [
    "_create_onnx_model(data,args_NN,model_NN,'NN_Membrane.onnx',x_dummy,scaled_input_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_definition_NN = load_onnx_neural_network_with_bounds('NN_Membrane.onnx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "formulation_NN = FullSpaceNNFormulation(network_definition_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tInputLayer(input_size=[7], output_size=[7])\tlinear\n",
      "1\tDenseLayer(input_size=[7], output_size=[32])\trelu\n",
      "2\tDenseLayer(input_size=[32], output_size=[32])\trelu\n",
      "3\tDenseLayer(input_size=[32], output_size=[8])\tlinear\n"
     ]
    }
   ],
   "source": [
    "for layer_id, layer in enumerate(network_definition_NN.layers):\n",
    "    print(f\"{layer_id}\\t{layer}\\t{layer.activation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[0]' to a numeric value\n",
      "`0` outside the bounds (0.002303625455624813, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[0]' to a numeric value\n",
      "`0` outside the bounds (0.002303625455624813, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[1]' to a numeric value\n",
      "`0` outside the bounds (0.00045880834803283796, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[2]' to a numeric value\n",
      "`0` outside the bounds (0.0022512226291679363, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[3]' to a numeric value\n",
      "`0` outside the bounds (0.10018982303101381, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[4]' to a numeric value\n",
      "`0` outside the bounds (0.25788606628182886, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[5]' to a numeric value\n",
      "`0` outside the bounds (0.4816711270961038, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[6]' to a numeric value\n",
      "`0` outside the bounds (0.056910004685567034, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "0.9869786500930786\n",
      "0.9869786500930786\n",
      "0.08980453759431839\n",
      "0.08980453759431839\n",
      "0.01095590554177761\n",
      "0.01095590554177761\n",
      "0.20008313655853271\n",
      "0.20008313655853271\n",
      "0.35781198740005493\n",
      "0.35781198740005493\n",
      "0.6735172271728516\n",
      "0.6735172271728516\n",
      "0.9051142334938049\n",
      "0.9051142334938049\n"
     ]
    }
   ],
   "source": [
    "inputs = ['F_MeOH',\n",
    "    'F_DME',\n",
    "    'F_H2O',\n",
    "    'F_N2',\n",
    "    'T_in',\n",
    "    'P_in',\n",
    "    'T_permeate']\n",
    "\n",
    "outputs = [\n",
    "    'F_MeOH_O',\n",
    "    'F_DME_O',\n",
    "    'F_H2O_O',\n",
    "    'F_H2O_M_O',\n",
    "    'F_N2_O',\n",
    "    'T_Out',\n",
    "    'T_Out_M',\n",
    "    'P_Out'\n",
    "]\n",
    "model = pyo.ConcreteModel()\n",
    "\n",
    "# create an OMLT block for the neural network and build its formulation\n",
    "model.membrane= OmltBlock()\n",
    "model.membrane.build_formulation(formulation_NN)\n",
    "model.membrane.inputs[0]\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    model.membrane.inputs[i] = x_dummy[i].item()\n",
    "    print(pyo.value(model.membrane.inputs[i]))\n",
    "    print(x_dummy[i].item())\n",
    "    model.membrane.inputs[i].setlb(lb[i])\n",
    "    model.membrane.inputs[i].setub(ub[i])\n",
    "\n",
    "for i in range(len(outputs)):\n",
    "    model.membrane.outputs[i] = 0.0\n",
    "    model.membrane.outputs[i].setlb(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tin_idx = inputs.index('T_in')\n",
    "Tm_idx = inputs.index('T_permeate')\n",
    "F_MeOH_idx = inputs.index('F_MeOH')\n",
    "F_DME_idx = inputs.index('F_DME')\n",
    "F_H2O_idx = inputs.index('F_H2O')\n",
    "F_N2_idx = inputs.index('F_N2')\n",
    "P_in_idx = inputs.index('P_in')\n",
    "\n",
    "FMeOh_O_idx = outputs.index('F_MeOH_O')\n",
    "FDME_O_idx = outputs.index('F_DME_O')\n",
    "FH2O_O_idx = outputs.index('F_H2O_O')\n",
    "FH2O_M_O_idx = outputs.index('F_H2O_M_O')\n",
    "FN2_O_idx = outputs.index('F_N2_O')\n",
    "TOut_idx = outputs.index('T_Out')\n",
    "TOut_M_idx = outputs.index('T_Out_M')\n",
    "POut_idx = outputs.index('P_Out')\n",
    "\n",
    "def Tin_bounds(m):\n",
    "    return (460,m.membrane.inputs[Tin_idx]*x_factor[Tin_idx],1000)\n",
    "\n",
    "def Tout_bounds(m):\n",
    "    return (460,y_factor[TOut_idx]*m.membrane.outputs[TOut_idx],1000)\n",
    "\n",
    "def TOut_mem_bounds(m):\n",
    "    return (283.15,y_factor[TOut_M_idx]*m.membrane.outputs[TOut_M_idx],450)\n",
    "\n",
    "def T_mem_bounds(m):\n",
    "    return (283.15,m.membrane.inputs[Tm_idx]*x_factor[Tm_idx],450)\n",
    "\n",
    "def TFlow_bounds(m):\n",
    "    FMeOh = m.membrane.inputs[F_MeOH_idx]*x_factor[F_MeOH_idx]\n",
    "    FDME = m.membrane.inputs[F_DME_idx]*x_factor[F_DME_idx]\n",
    "    FH2O = m.membrane.inputs[F_H2O_idx]*x_factor[F_H2O_idx]\n",
    "    FN2 = m.membrane.inputs[F_N2_idx]*x_factor[F_N2_idx]\n",
    "    Ftot = FMeOh + FDME + FH2O + FN2\n",
    "    return (1, Ftot, 100)\n",
    "\n",
    "\n",
    "def P_bounds(m):\n",
    "    return (13e5, m.membrane.inputs[P_in_idx]*x_factor[P_in_idx], 27e5)\n",
    "\n",
    "def POut_bounds(m):\n",
    "    return (13e5, m.membrane.outputs[POut_idx]*y_factor[POut_idx], 27e5)\n",
    "\n",
    "def Mas_Bal(m):\n",
    "    FMeOh = m.membrane.inputs[F_MeOH_idx]*x_factor[F_MeOH_idx]\n",
    "    FDME = m.membrane.inputs[F_DME_idx]*x_factor[F_DME_idx]\n",
    "    FH2O = m.membrane.inputs[F_H2O_idx]*x_factor[F_H2O_idx]\n",
    "    FN2 = m.membrane.inputs[F_N2_idx]*x_factor[F_N2_idx]\n",
    "    FMeOh_O = m.membrane.outputs[FMeOh_O_idx]*y_factor[FMeOh_O_idx]\n",
    "    FDME_O = m.membrane.outputs[FDME_O_idx]*y_factor[FDME_O_idx]\n",
    "    FH2O_O = m.membrane.outputs[FH2O_O_idx]*y_factor[FH2O_O_idx]\n",
    "    FN2_O = m.membrane.outputs[FN2_O_idx]*y_factor[FN2_O_idx]\n",
    "    FH2O_M_O = m.membrane.outputs[FH2O_M_O_idx]*y_factor[FH2O_M_O_idx]\n",
    "\n",
    "    In = FMeOh + FDME + FH2O + FN2\n",
    "    Out = FMeOh_O + FDME_O + FH2O_O + FN2_O + FH2O_M_O\n",
    "    MassBal = abs(In - Out)\n",
    "    return (0, MassBal, 1e-6)\n",
    "\n",
    "def Flow_Nitrog(m):\n",
    "    FN2 = m.membrane.inputs[F_N2_idx]*x_factor[F_N2_idx]\n",
    "    FN2_O = m.membrane.outputs[FN2_O_idx]*y_factor[FN2_O_idx]\n",
    "    \n",
    "    return (FN2-FN2_O == 0)\n",
    "\n",
    "def Flow_MEOH(m):\n",
    "    return m.membrane.inputs[F_MeOH_idx]*x_factor[F_MeOH_idx] == 0.93*15.58 \n",
    "\n",
    "def Flow_DME(m):\n",
    "    return m.membrane.inputs[F_DME_idx]*x_factor[F_DME_idx] == 0.06*15.58\n",
    "\n",
    "def Flow_H2O(m):\n",
    "    return m.membrane.inputs[F_H2O_idx]*x_factor[F_H2O_idx] == 0.01*15.58\n",
    "\n",
    "\n",
    "\n",
    "model.Tin_constr = pyo.Constraint(rule = Tin_bounds)\n",
    "model.Tm_constr = pyo.Constraint(rule = T_mem_bounds)\n",
    "model.TFlow_constr = pyo.Constraint(rule = TFlow_bounds)\n",
    "model.P_constr = pyo.Constraint(rule = P_bounds)\n",
    "model.MassBal = pyo.Constraint(rule = Mas_Bal)\n",
    "model.Flow_Nitrog = pyo.Constraint(rule = Flow_Nitrog)\n",
    "model.Tout_constr = pyo.Constraint(rule = Tout_bounds)\n",
    "model.Tout_M_constr = pyo.Constraint(rule = TOut_mem_bounds)\n",
    "\n",
    "model.Flow_MEOH = pyo.Constraint(rule = Flow_MEOH)\n",
    "model.Flow_DME = pyo.Constraint(rule = Flow_DME)\n",
    "model.Flow_H2O = pyo.Constraint(rule = Flow_H2O)\n",
    "\n",
    "model.POut_constr = pyo.Constraint(rule = POut_bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rule(m):\n",
    "    prices = {\n",
    "        \"MeOH\": 891*1e-6,  # Cost of Methanol in $/kg\n",
    "        \"DME\": 2021.84*1e-6,   # Cost of Dimethyl Ether in $/kg\n",
    "        \"H2O\": 0.29*1e-6,  # Cost of Water in $/kg\n",
    "        \"N2\": 121.254*1e-6  # Cost of Nitrogen in $/kg\n",
    "    }\n",
    "\n",
    "    MW = {\n",
    "        \"MeOH\": 32.04,  # MW of Methanol in g/mol\n",
    "        \"DME\": 46.069,   # Cost of Dimethyl Ether in $/kg\n",
    "        \"H2O\": 18.0152,  # Cost of Water in $/kg\n",
    "        \"N2\": 28.0134  # Cost of Nitrogen in $/kg\n",
    "    }\n",
    "\n",
    "    DME_O = m.membrane.outputs[outputs.index(\"F_DME_O\")]*y_factor[outputs.index(\"F_DME_O\")]\n",
    "    H2O_O = m.membrane.outputs[outputs.index(\"F_H2O_O\")]*y_factor[outputs.index(\"F_H2O_O\")]\n",
    "    H2O_M_O = m.membrane.outputs[outputs.index(\"F_H2O_M_O\")]*y_factor[outputs.index(\"F_H2O_M_O\")]\n",
    "    MeOH_In = m.membrane.inputs[inputs.index(\"F_MeOH\")]*x_factor[inputs.index(\"F_MeOH\")]\n",
    "    N2_In = m.membrane.inputs[inputs.index(\"F_N2\")]*x_factor[inputs.index(\"F_N2\")]\n",
    "    DME_In = m.membrane.inputs[inputs.index(\"F_DME\")]*x_factor[inputs.index(\"F_DME\")]\n",
    "\n",
    "    product_profit = prices[\"DME\"]*DME_O * MW[\"DME\"] + prices[\"H2O\"]*(H2O_O + H2O_M_O) * MW[\"H2O\"]\n",
    "\n",
    "    feedstock_cost = prices[\"MeOH\"]*MeOH_In * MW[\"MeOH\"] + prices[\"N2\"]*N2_In * MW[\"N2\"] + prices[\"DME\"]*DME_O * MW[\"DME\"]\n",
    "    return product_profit - feedstock_cost\n",
    "\n",
    "model.objective = pyo.Objective(rule = objective_rule, sense = pyo.maximize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipopt 3.14.6: \n",
      "==> Warning: Treating 64 binary and 0 integer variables as continuous.\n",
      "\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.14.6, running with linear solver MUMPS 5.2.1.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:     1625\n",
      "Number of nonzeros in inequality constraint Jacobian.:      527\n",
      "Number of nonzeros in Lagrangian Hessian.............:       45\n",
      "\n",
      "Total number of variables............................:      244\n",
      "                     variables with only lower bounds:        8\n",
      "                variables with lower and upper bounds:      228\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:      114\n",
      "Total number of inequality constraints...............:      264\n",
      "        inequality constraints with only lower bounds:       64\n",
      "   inequality constraints with lower and upper bounds:        8\n",
      "        inequality constraints with only upper bounds:      192\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  4.8164620e-01 1.27e+06 7.25e-01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  4.8164608e-01 1.27e+06 9.93e-01  -1.0 2.16e+01    -  6.68e-03 1.02e-05f  1\n",
      "   2  4.8147351e-01 1.26e+06 9.87e-01  -1.0 1.88e+01    -  1.25e-02 1.34e-02f  1\n",
      "   3  4.8085325e-01 1.21e+06 1.28e+00  -1.0 1.47e+01    -  1.88e-02 3.58e-02f  1\n",
      "   4  4.8024632e-01 1.12e+06 1.29e+00  -1.0 1.13e+01    -  6.62e-02 7.05e-02f  1\n",
      "   5  4.8036047e-01 1.10e+06 3.41e+00  -1.0 6.60e+00    -  5.83e-02 2.32e-02f  1\n",
      "   6  4.8035173e-01 1.10e+06 2.33e+02  -1.0 5.02e+01    -  3.49e-02 1.32e-03h  1\n",
      "   7  4.8034330e-01 1.08e+06 1.72e+03  -1.0 6.09e+01    -  6.48e-02 1.18e-02f  1\n",
      "   8  4.8034306e-01 1.08e+06 9.65e+05  -1.0 5.67e+01    -  5.76e-02 1.22e-04h  1\n",
      "   9r 4.8034306e-01 1.08e+06 9.99e+02   1.9 0.00e+00    -  0.00e+00 3.51e-07R  5\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10r 4.8047853e-01 1.07e+06 1.01e+03   1.9 3.76e+04    -  1.15e-04 2.04e-05f  1\n",
      "  11r 4.8011398e-01 8.16e+05 9.99e+02   1.2 3.95e+04    -  1.41e-04 5.78e-04f  1\n",
      "  12  4.8011390e-01 8.16e+05 1.22e+04  -1.0 8.54e+00    -  1.66e-01 1.57e-05h  1\n",
      "  13r 4.8011390e-01 8.16e+05 9.99e+02   1.8 0.00e+00    -  0.00e+00 3.61e-07R  5\n",
      "  14r 4.8058135e-01 7.85e+05 1.08e+03   1.8 2.64e+04    -  8.61e-04 8.03e-05f  1\n",
      "  15r 4.8044335e-01 1.75e+05 9.97e+02   1.1 2.01e+04    -  1.29e-03 2.24e-03f  1\n",
      "  16r 4.8110588e-01 5.28e+04 1.07e+03   1.1 2.18e+03    -  3.43e-03 2.55e-03f  1\n",
      "  17r 4.8237231e-01 2.39e+04 1.01e+03   1.1 9.06e+02    -  2.54e-03 3.07e-03f  1\n",
      "  18r 4.8612038e-01 1.06e+02 1.38e+03   1.1 5.11e+02    -  1.30e-02 9.22e-03f  1\n",
      "  19r 4.9633294e-01 1.06e+02 6.58e+03   1.1 1.28e+02    -  7.76e-02 2.35e-02f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  20r 5.2262674e-01 1.06e+02 7.16e+03   1.1 1.84e+02    -  1.26e-01 1.11e-01f  1\n",
      "  21r 5.5252829e-01 1.06e+02 5.70e+04   1.1 1.29e+02    -  8.99e-01 2.36e-01f  1\n",
      "  22r 5.8261768e-01 1.06e+02 4.16e+03   1.1 8.86e+00    -  1.00e+00 1.00e+00f  1\n",
      "  23r 5.7685390e-01 1.06e+02 2.52e+03  -0.3 3.70e+00    -  8.25e-01 7.30e-01f  1\n",
      "  24r 5.7453503e-01 1.06e+02 7.09e+02  -0.3 9.49e-01    -  9.44e-01 7.18e-01f  1\n",
      "  25r 5.6790070e-01 1.06e+02 3.76e+02  -0.3 1.95e+00    -  1.00e+00 1.00e+00f  1\n",
      "  26r 5.6629278e-01 1.06e+02 3.72e+02  -0.3 8.21e-01    -  1.00e+00 1.00e+00f  1\n",
      "  27r 5.6629652e-01 1.06e+02 4.81e-06  -0.3 2.47e-02    -  1.00e+00 1.00e+00h  1\n",
      "  28r 5.5254583e-01 1.06e+02 2.90e+01  -3.9 4.54e+00    -  8.20e-01 8.91e-01f  1\n",
      "  29r 5.5136076e-01 1.06e+02 7.74e-01  -3.9 3.97e-01    -  9.81e-01 9.73e-01f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  30r 5.1850746e-01 1.06e+02 2.01e-01  -3.9 1.15e+01    -  7.20e-01 1.00e+00f  1\n",
      "  31r 4.8978793e-01 1.06e+02 2.04e+00  -3.9 9.64e+00    -  7.30e-01 1.00e+00f  1\n",
      "  32r 4.7644537e-01 1.06e+02 1.38e-09  -3.9 4.50e+00    -  1.00e+00 1.00e+00f  1\n",
      "  33r 4.6313314e-01 1.06e+02 8.70e-01  -5.8 4.64e+00    -  7.37e-01 8.45e-01f  1\n",
      "  34r 4.6179674e-01 1.06e+02 1.80e+00  -5.8 4.08e-01    -  1.00e+00 9.64e-01f  1\n",
      "  35r 4.5645386e-01 1.06e+02 2.46e+01  -5.8 1.57e+00    -  9.60e-01 1.00e+00f  1\n",
      "  36r 4.5499736e-01 1.06e+02 1.64e-11  -5.8 4.29e-01    -  1.00e+00 1.00e+00f  1\n",
      "  37r 4.5216413e-01 1.06e+02 3.77e+01  -8.7 1.09e+00    -  9.30e-01 7.63e-01f  1\n",
      "  38r 4.5198300e-01 1.06e+02 8.35e-01  -8.7 5.51e-02    -  9.63e-01 9.68e-01f  1\n",
      "\n",
      "Number of Iterations....: 38\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   4.5074274140269022e-01    4.5074274140269022e-01\n",
      "Dual infeasibility......:   4.1917069844547045e-01    4.1917069844547045e-01\n",
      "Constraint violation....:   6.0176930303473554e+01    1.0637672670077102e+02\n",
      "Variable bound violation:   9.9999790670324273e-09    9.9999790670324273e-09\n",
      "Complementarity.........:   1.1639156587414911e-08    1.1639156587414911e-08\n",
      "Overall NLP error.......:   6.0176930303473554e+01    1.0637672670077102e+02\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 50\n",
      "Number of objective gradient evaluations             = 14\n",
      "Number of equality constraint evaluations            = 50\n",
      "Number of inequality constraint evaluations          = 50\n",
      "Number of equality constraint Jacobian evaluations   = 42\n",
      "Number of inequality constraint Jacobian evaluations = 42\n",
      "Number of Lagrangian Hessian evaluations             = 39\n",
      "Total seconds in IPOPT                               = 0.205\n",
      "\n",
      "EXIT: Converged to a point of local infeasibility. Problem may be infeasible.\n",
      "WARNING: Loading a SolverResults object with a warning status into\n",
      "model.name=\"unknown\";\n",
      "    - termination condition: infeasible\n",
      "    - message from solver: Ipopt 3.14.6\\x3a Converged to a locally infeasible\n",
      "      point. Problem may be infeasible.\n"
     ]
    }
   ],
   "source": [
    "solver = pyo.SolverFactory(\"ipopt\")\n",
    "status = solver.solve(model, tee=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------------+--------------------+------------+\n",
      "| Input Parameter   | Value               | Output Parameter   | Value      |\n",
      "+===================+=====================+====================+============+\n",
      "| F_MeOH            | 14.489400000000002  | F_MeOH_O           | 2.00306    |\n",
      "+-------------------+---------------------+--------------------+------------+\n",
      "| F_DME             | 0.9348              | F_DME_O            | 6.26722    |\n",
      "+-------------------+---------------------+--------------------+------------+\n",
      "| F_H2O             | 0.15580000000000002 | F_H2O_O            | 2.10138    |\n",
      "+-------------------+---------------------+--------------------+------------+\n",
      "| -                 | -                   | F_H2O_M_O          | 5.20834    |\n",
      "+-------------------+---------------------+--------------------+------------+\n",
      "| F_N2              | 10.934834663653753  | F_N2_O             | 10.9348    |\n",
      "+-------------------+---------------------+--------------------+------------+\n",
      "| T_in              | 460.03591440915733  | T_Out              | 994.496    |\n",
      "+-------------------+---------------------+--------------------+------------+\n",
      "| P_in              | 1300573.7959855646  | P_Out              | 1.3002e+06 |\n",
      "+-------------------+---------------------+--------------------+------------+\n",
      "| T_In_M            | 176.77327046772896  | T_Out_M            | 283.169    |\n",
      "+-------------------+---------------------+--------------------+------------+\n",
      "+-----------------+----------+\n",
      "| MeOH Conversion | 0.861757 |\n",
      "+-----------------+----------+\n",
      "Mass Balance Violation: 5.000748579675474e-07\n"
     ]
    }
   ],
   "source": [
    "F_MEOH_IN = pyo.value(model.membrane.inputs[inputs.index(\"F_MeOH\")])*x_factor[inputs.index(\"F_MeOH\")]\n",
    "F_MEOH_OUT = pyo.value(model.membrane.outputs[outputs.index(\"F_MeOH_O\")])*y_factor[outputs.index(\"F_MeOH_O\")]\n",
    "\n",
    "F_DEM_IN = pyo.value(model.membrane.inputs[inputs.index(\"F_DME\")])*x_factor[inputs.index(\"F_DME\")]\n",
    "F_DME_OUT = pyo.value(model.membrane.outputs[outputs.index(\"F_DME_O\")])*y_factor[outputs.index(\"F_DME_O\")]\n",
    "\n",
    "F_H2O_IN = pyo.value(model.membrane.inputs[inputs.index(\"F_H2O\")])*x_factor[inputs.index(\"F_H2O\")]\n",
    "F_H2O_OUT = pyo.value(model.membrane.outputs[outputs.index(\"F_H2O_O\")])*y_factor[outputs.index(\"F_H2O_O\")]\n",
    "F_H2O_M_OUT = pyo.value(model.membrane.outputs[outputs.index(\"F_H2O_M_O\")])*y_factor[outputs.index(\"F_H2O_M_O\")]\n",
    "\n",
    "F_N2_IN = pyo.value(model.membrane.inputs[inputs.index(\"F_N2\")])*x_factor[inputs.index(\"F_N2\")]\n",
    "F_N2_OUT = pyo.value(model.membrane.outputs[outputs.index(\"F_N2_O\")])*y_factor[outputs.index(\"F_N2_O\")]\n",
    "\n",
    "T_IN = pyo.value(model.membrane.inputs[inputs.index(\"T_in\")])*x_factor[inputs.index(\"T_in\")]\n",
    "T_M_IN = pyo.value(model.membrane.inputs[inputs.index(\"T_permeate\")])*x_factor[inputs.index(\"T_permeate\")]\n",
    "T_OUT = pyo.value(model.membrane.outputs[outputs.index(\"T_Out\")])*y_factor[outputs.index(\"T_Out\")]\n",
    "T_M_OUT = pyo.value(model.membrane.outputs[outputs.index(\"T_Out_M\")])*y_factor[outputs.index(\"T_Out_M\")]\n",
    "\n",
    "P_IN = pyo.value(model.membrane.inputs[inputs.index(\"P_in\")])*x_factor[inputs.index(\"P_in\")]\n",
    "P_OUT = pyo.value(model.membrane.outputs[outputs.index(\"P_Out\")])*y_factor[outputs.index(\"P_Out\")]\n",
    "\n",
    "CONVERSION = (F_MEOH_IN - F_MEOH_OUT)/F_MEOH_IN\n",
    "Mas_Bal = pyo.value(model.MassBal)\n",
    "\n",
    "data_tabulate = [\n",
    "    [\"Input Parameter\",\"Value\",\"Output Parameter\",\"Value\"],\n",
    "    [\"F_MeOH\", F_MEOH_IN, \"F_MeOH_O\", F_MEOH_OUT],\n",
    "    [\"F_DME\", F_DEM_IN, \"F_DME_O\", F_DME_OUT],\n",
    "    [\"F_H2O\", F_H2O_IN, \"F_H2O_O\", F_H2O_OUT],\n",
    "    [\"-\", \"-\", \"F_H2O_M_O\", F_H2O_M_OUT],\n",
    "    [\"F_N2\", F_N2_IN, \"F_N2_O\", F_N2_OUT],\n",
    "    [\"T_in\", T_IN, \"T_Out\", T_OUT],\n",
    "    [\"P_in\", P_IN, \"P_Out\", P_OUT],\n",
    "    [\"T_In_M\", T_M_IN, \"T_Out_M\", T_M_OUT],\n",
    "]\n",
    "\n",
    "conversion_table = [\n",
    "    [\"MeOH Conversion\", CONVERSION]\n",
    "]\n",
    "\n",
    "print(tabulate(data_tabulate, headers=\"firstrow\", tablefmt=\"grid\", colalign=(\"left\", \"left\", \"left\", \"left\")))\n",
    "print(tabulate(conversion_table, tablefmt=\"grid\", colalign=(\"left\", \"left\")))\n",
    "print(f\"Mass Balance Violation: {Mas_Bal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.46831994e+01 1.04111445e+01 1.42231966e+01 9.99584502e+01\n",
      " 7.26638589e+02 2.69926289e+06 1.76773269e+02]\n"
     ]
    }
   ],
   "source": [
    "print(x_factor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemfigmkr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
