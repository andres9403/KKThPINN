{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 08:03:41.414428: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-13 08:03:41.424102: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736777021.434363  432290 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736777021.437544  432290 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-13 08:03:41.451327: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from main import main\n",
    "from utils import LoadData, LoadModel, load_data\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import pandas as pd\n",
    "# pyomo for optimization\n",
    "import pyomo.environ as pyo\n",
    "\n",
    "# pytorch for training neural network\n",
    "import torch.onnx\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# omlt for interfacing our neural network with pyomo\n",
    "import onnx\n",
    "from omlt import OffsetScaling, OmltBlock\n",
    "from omlt.io.onnx import (\n",
    "    load_onnx_neural_network_with_bounds,\n",
    "    write_onnx_model_with_bounds,\n",
    "    load_onnx_neural_network,\n",
    ")\n",
    "from omlt.neuralnet import (FullSpaceNNFormulation, \n",
    "    ReluComplementarityFormulation, \n",
    "    ReluPartitionFormulation,\n",
    "    ReducedSpaceNNFormulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_arguments(model,model_id,system,scenario):    \n",
    "    if system == 'membrane':\n",
    "        args = argparse.Namespace(\n",
    "            input_dim=7,\n",
    "            hidden_dim=32,\n",
    "            hidden_num=2,\n",
    "            z0_dim=8,\n",
    "            optimizer='adam',\n",
    "            epochs=1000,\n",
    "            batch_size=16,\n",
    "            lr=1e-4,\n",
    "            mu=1,\n",
    "            max_subiter=500,\n",
    "            eta=0.8,\n",
    "            sigma=2,\n",
    "            mu_safe=1e+9,\n",
    "            dtype=32,\n",
    "            dataset_path='/home/andresfel9403/KKThNN/KKThPINN/benchmark_membrane.csv',\n",
    "            val_ratio=0.2,\n",
    "            job='train',\n",
    "            runs=10)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    args.model = model\n",
    "    args.model_id = model_id\n",
    "    args.dataset_type = system\n",
    "    args.scenario = scenario\n",
    "        \n",
    "    \n",
    "    if args.model == 'NN':\n",
    "        args.loss_type = 'MSE'\n",
    "    elif args.model == 'PINN':\n",
    "        args.loss_type = 'PINN'\n",
    "    elif args.model == 'KKThPINN':\n",
    "        args.loss_type = 'MSE'\n",
    "    elif args.model == 'AugLagNN':\n",
    "        args.loss_type = 'MSE'\n",
    "    elif args.model == 'ECNN':\n",
    "        args.loss_type = 'MSE'\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['F_MeOH',\n",
    "    'F_DME',\n",
    "    'F_H2O',\n",
    "    'F_N2',\n",
    "    'T_in',\n",
    "    'P_in',\n",
    "    'T_permeate']\n",
    "\n",
    "outputs = [\n",
    "    'F_MeOH_O',\n",
    "    'F_DME_O',\n",
    "    'F_H2O_O',\n",
    "    'F_H2O_M_O',\n",
    "    'F_N2_O',\n",
    "    'T_Out',\n",
    "    'T_Out_M',\n",
    "    'P_Out'\n",
    "]\n",
    "\n",
    "columns = inputs+outputs\n",
    "\n",
    "df = pd.read_csv(\"benchmark_membrane.csv\", usecols = columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_NN = add_arguments('NN','MembraneT_NN','membrane','demonstration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of A: torch.float32, type of B: torch.float32, type of b: torch.float32\n",
      "train set size: 614, val set size: 204, test set size: 204\n",
      "Start Training...\n",
      "epoch: 00050 loss_train: 0.01069 loss_val: 0.01068 violation_train: 8.32718 violation_val: 8.09988\n",
      "epoch: 00100 loss_train: 0.00197 loss_val: 0.00235 violation_train: 2.01154 violation_val: 1.82959\n",
      "epoch: 00150 loss_train: 0.00105 loss_val: 0.00159 violation_train: 0.57898 violation_val: 0.73128\n",
      "epoch: 00200 loss_train: 0.00101 loss_val: 0.00150 violation_train: 0.64267 violation_val: 0.83612\n",
      "epoch: 00250 loss_train: 0.00090 loss_val: 0.00135 violation_train: 0.74590 violation_val: 0.90038\n",
      "epoch: 00300 loss_train: 0.00071 loss_val: 0.00111 violation_train: 0.65210 violation_val: 0.64794\n",
      "epoch: 00350 loss_train: 0.00057 loss_val: 0.00093 violation_train: 0.60743 violation_val: 0.58844\n",
      "epoch: 00400 loss_train: 0.00046 loss_val: 0.00080 violation_train: 0.42439 violation_val: 0.49596\n",
      "epoch: 00450 loss_train: 0.00038 loss_val: 0.00071 violation_train: 0.38084 violation_val: 0.37875\n",
      "epoch: 00500 loss_train: 0.00035 loss_val: 0.00065 violation_train: 0.30371 violation_val: 0.45158\n",
      "epoch: 00550 loss_train: 0.00032 loss_val: 0.00061 violation_train: 0.34746 violation_val: 0.42519\n",
      "epoch: 00600 loss_train: 0.00030 loss_val: 0.00058 violation_train: 0.34573 violation_val: 0.44287\n",
      "epoch: 00650 loss_train: 0.00029 loss_val: 0.00057 violation_train: 0.36614 violation_val: 0.46456\n",
      "epoch: 00700 loss_train: 0.00028 loss_val: 0.00055 violation_train: 0.38392 violation_val: 0.51259\n",
      "epoch: 00750 loss_train: 0.00028 loss_val: 0.00052 violation_train: 0.40792 violation_val: 0.49640\n",
      "epoch: 00800 loss_train: 0.00026 loss_val: 0.00050 violation_train: 0.34684 violation_val: 0.61167\n",
      "epoch: 00850 loss_train: 0.00025 loss_val: 0.00048 violation_train: 0.32985 violation_val: 0.43868\n",
      "epoch: 00900 loss_train: 0.00023 loss_val: 0.00046 violation_train: 0.27985 violation_val: 0.37847\n",
      "epoch: 00950 loss_train: 0.00023 loss_val: 0.00045 violation_train: 0.25748 violation_val: 0.36969\n",
      "epoch: 01000 loss_train: 0.00021 loss_val: 0.00044 violation_train: 0.21263 violation_val: 0.30465\n",
      "Finished!\n",
      "{'rmse_total': np.float64(0.015962621000429836), 'rmse_unconstrained': np.float64(0.00465188510344386), 'rmse_constrained': np.float64(0.004247221232973271), 'violation': 0.27992379665374756, 'post_rmse_total': np.float64(0.01589141561224709), 'post_rmse_unconstrained': np.float64(0.003770020148364148), 'post_rmse_constrained': np.float64(0.004344982683474422)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andresfel9403/KKThNN/KKThPINN/train.py:264: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(PATH)\n"
     ]
    }
   ],
   "source": [
    "main(args_NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the arguments depending on the number of inputs, hidden and output layers, we can train the model selecting the Neural Network model (NN or KKThPINN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of A: torch.float32, type of B: torch.float32, type of b: torch.float32\n",
      "train set size: 614, val set size: 204, test set size: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_432290/2941437368.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(PATH)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, scaling = load_data(args_NN.dataset_path)\n",
    "inputs = dataset[:,:7]\n",
    "outputs = dataset[:,7:]\n",
    "\n",
    "data = LoadData(args_NN)\n",
    "model_NN = LoadModel(args_NN, data)\n",
    "PATH = '/home/andresfel9403/KKThNN/models/membrane/NN/0.2/None_0.2_9.pth'\n",
    "checkpoint = torch.load(PATH)\n",
    "model_NN.load_state_dict(checkpoint['state_dict'])\n",
    "#model_NN.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.46831994e+01 1.04111445e+01 1.42231966e+01 9.99584502e+01\n",
      " 7.26638589e+02 2.69926289e+06 1.76773269e+02]\n"
     ]
    }
   ],
   "source": [
    "x_factor = scaling.scale_[:7]\n",
    "y_factor = scaling.scale_[7:]\n",
    "\n",
    "print(x_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = scaler = OffsetScaling(\n",
    "    offset_inputs={i: 0 for i in range(len(x_factor))},\n",
    "    factor_inputs={i: x_factor[i] for i in range(len(x_factor))},\n",
    "    offset_outputs={i: 0 for i in range(len(y_factor))},\n",
    "    factor_outputs={i: y_factor[i] for i in range(len(y_factor))},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "x_dummy = torch.from_numpy(inputs[0]).float()\n",
    "ub = np.max(inputs, 0)\n",
    "lb = np.min(inputs, 0)\n",
    "\n",
    "scaled_input_bounds = {i: (lb[i], ub[i]) for i in range(len(inputs[0]))}\n",
    "print(ub.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_weights(original_model, modified_model):\n",
    "    with torch.no_grad():\n",
    "        for original_layer, modified_layer in zip(original_model.layers, modified_model.layers):\n",
    "            if isinstance(original_layer, nn.Linear) and isinstance(modified_layer, nn.Linear):\n",
    "                modified_layer.weight.copy_(original_layer.weight)\n",
    "                modified_layer.bias.copy_(original_layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_onnx_model(data,args,model,file_path,x,input_bounds):\n",
    "    args.model='NN'\n",
    "    print('Saving standard model')\n",
    "    modified_model = LoadModel(args,data)\n",
    "    transfer_weights(model,modified_model)\n",
    "    create_onnx_model(data,modified_model,file_path,x,input_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_onnx_model(data,model,file_path,x,input_bounds):\n",
    "    \n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        x,\n",
    "        file_path,\n",
    "        input_names=[\"input\"],\n",
    "        dynamo = False\n",
    "    )\n",
    "    write_onnx_model_with_bounds(file_path, None, input_bounds)\n",
    "    print(f\"Wrote PyTorch Onnx model to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving standard model\n",
      "Wrote PyTorch Onnx model to NN_Membrane.onnx\n"
     ]
    }
   ],
   "source": [
    "_create_onnx_model(data,args_NN,model_NN,'NN_Membrane.onnx',x_dummy,scaled_input_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_definition_NN = load_onnx_neural_network_with_bounds('NN_Membrane.onnx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "formulation_NN = FullSpaceNNFormulation(network_definition_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tInputLayer(input_size=[7], output_size=[7])\tlinear\n",
      "1\tDenseLayer(input_size=[7], output_size=[32])\trelu\n",
      "2\tDenseLayer(input_size=[32], output_size=[32])\trelu\n",
      "3\tDenseLayer(input_size=[32], output_size=[8])\tlinear\n"
     ]
    }
   ],
   "source": [
    "for layer_id, layer in enumerate(network_definition_NN.layers):\n",
    "    print(f\"{layer_id}\\t{layer}\\t{layer.activation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[0]' to a numeric value\n",
      "`0` outside the bounds (0.002303625455624813, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[0]' to a numeric value\n",
      "`0` outside the bounds (0.002303625455624813, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[1]' to a numeric value\n",
      "`0` outside the bounds (0.00045880834803283796, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[2]' to a numeric value\n",
      "`0` outside the bounds (0.0022512226291679363, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[3]' to a numeric value\n",
      "`0` outside the bounds (0.10018982303101381, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[4]' to a numeric value\n",
      "`0` outside the bounds (0.25788606628182886, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[5]' to a numeric value\n",
      "`0` outside the bounds (0.4816711270961038, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[6]' to a numeric value\n",
      "`0` outside the bounds (0.056910004685567034, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n"
     ]
    }
   ],
   "source": [
    "inputs = ['F_MeOH',\n",
    "    'F_DME',\n",
    "    'F_H2O',\n",
    "    'F_N2',\n",
    "    'T_in',\n",
    "    'P_in',\n",
    "    'T_permeate']\n",
    "\n",
    "outputs = [\n",
    "    'F_MeOH_O',\n",
    "    'F_DME_O',\n",
    "    'F_H2O_O',\n",
    "    'F_H2O_M_O',\n",
    "    'F_N2_O',\n",
    "    'T_Out',\n",
    "    'T_Out_M',\n",
    "    'P_Out'\n",
    "]\n",
    "model = pyo.ConcreteModel()\n",
    "\n",
    "# create an OMLT block for the neural network and build its formulation\n",
    "model.membrane= OmltBlock()\n",
    "model.membrane.build_formulation(formulation_NN)\n",
    "model.membrane.inputs[0]\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    model.membrane.inputs[i] = x_dummy[i].item()\n",
    "    model.membrane.inputs[i].setlb(lb[i])\n",
    "    model.membrane.inputs[i].setub(ub[i])\n",
    "\n",
    "for i in range(len(outputs)):\n",
    "    model.membrane.outputs[i] = 0.0\n",
    "    model.membrane.outputs[i].setlb(0.0)\n",
    "\n",
    "\n",
    "# model.sections = pyo.Set(initialize=[\"retentate\", \"permeate\"], doc=\"sections in the model\")\n",
    "# model.components = pyo.Set(initialize=[\"MeOH\", \"DME\", \"H2O\", \"N2\"], doc=\"Components in the model\")\n",
    "\n",
    "print(pyo.value(model.membrane.inputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Tin_idx = inputs.index('T_in')\n",
    "Tm_idx = inputs.index('T_permeate')\n",
    "F_MeOH_idx = inputs.index('F_MeOH')\n",
    "F_DME_idx = inputs.index('F_DME')\n",
    "F_H2O_idx = inputs.index('F_H2O')\n",
    "F_N2_idx = inputs.index('F_N2')\n",
    "P_in_idx = inputs.index('P_in')\n",
    "\n",
    "FMeOh_O_idx = outputs.index('F_MeOH_O')\n",
    "FDME_O_idx = outputs.index('F_DME_O')\n",
    "FH2O_O_idx = outputs.index('F_H2O_O')\n",
    "FH2O_M_O_idx = outputs.index('F_H2O_M_O')\n",
    "FN2_O_idx = outputs.index('F_N2_O')\n",
    "TOut_idx = outputs.index('T_Out')\n",
    "TOut_M_idx = outputs.index('T_Out_M')\n",
    "POut_idx = outputs.index('P_Out')\n",
    "\n",
    "def Tin_bounds(m):\n",
    "    return (460,m.membrane.inputs[Tin_idx]*x_factor[Tin_idx],1000)\n",
    "\n",
    "def Tout_bounds(m):\n",
    "    return (460,y_factor[TOut_idx]*m.membrane.outputs[TOut_idx],1000)\n",
    "\n",
    "def TOut_mem_bounds(m):\n",
    "    return (283.15,y_factor[TOut_M_idx]*m.membrane.outputs[TOut_M_idx],450)\n",
    "\n",
    "def T_mem_bounds(m):\n",
    "    return (283.15,m.membrane.inputs[Tm_idx]*x_factor[Tm_idx],450)\n",
    "\n",
    "def TFlow_bounds(m):\n",
    "    FMeOh = m.membrane.inputs[F_MeOH_idx]*x_factor[F_MeOH_idx]\n",
    "    FDME = m.membrane.inputs[F_DME_idx]*x_factor[F_DME_idx]\n",
    "    FH2O = m.membrane.inputs[F_H2O_idx]*x_factor[F_H2O_idx]\n",
    "    FN2 = m.membrane.inputs[F_N2_idx]*x_factor[F_N2_idx]\n",
    "    Ftot = FMeOh + FDME + FH2O + FN2\n",
    "    return (1, Ftot, 100)\n",
    "\n",
    "def Flow_DME(m):\n",
    "\n",
    "    return (0, m.membrane.inputs[F_DME_idx], 0.005)\n",
    "\n",
    "def P_bounds(m):\n",
    "    return (13e5/x_factor[P_in_idx], m.membrane.inputs[P_in_idx], 27e5)\n",
    "\n",
    "def Mas_Bal(m):\n",
    "    FMeOh = m.membrane.inputs[F_MeOH_idx]*x_factor[F_MeOH_idx]\n",
    "    FDME = m.membrane.inputs[F_DME_idx]*x_factor[F_DME_idx]\n",
    "    FH2O = m.membrane.inputs[F_H2O_idx]*x_factor[F_H2O_idx]\n",
    "    FN2 = m.membrane.inputs[F_N2_idx]*x_factor[F_N2_idx]\n",
    "    FMeOh_O = m.membrane.outputs[FMeOh_O_idx]*y_factor[FMeOh_O_idx]\n",
    "    FDME_O = m.membrane.outputs[FDME_O_idx]*y_factor[FDME_O_idx]\n",
    "    FH2O_O = m.membrane.outputs[FH2O_O_idx]*y_factor[FH2O_O_idx]\n",
    "    FN2_O = m.membrane.outputs[FN2_O_idx]*y_factor[FN2_O_idx]\n",
    "    FH2O_M_O = m.membrane.outputs[FH2O_M_O_idx]*y_factor[FH2O_M_O_idx]\n",
    "\n",
    "    In = FMeOh + FDME + FH2O + FN2\n",
    "    Out = FMeOh_O + FDME_O + FH2O_O + FN2_O + FH2O_M_O\n",
    "    MassBal = abs(In - Out)\n",
    "    return (0, MassBal, 1e-6)\n",
    "\n",
    "def Flow_Nitrog(m):\n",
    "    FN2 = m.membrane.inputs[F_N2_idx]*x_factor[F_N2_idx]\n",
    "    FN2_O = m.membrane.outputs[FN2_O_idx]*y_factor[FN2_O_idx]\n",
    "    \n",
    "    return (FN2-FN2_O == 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.Tin_constr = pyo.Constraint(rule = Tin_bounds)\n",
    "model.Tm_constr = pyo.Constraint(rule = T_mem_bounds)\n",
    "model.TFlow_constr = pyo.Constraint(rule = TFlow_bounds)\n",
    "model.P_constr = pyo.Constraint(rule = P_bounds)\n",
    "model.MassBal = pyo.Constraint(rule = Mas_Bal)\n",
    "model.Flow_Nitrog = pyo.Constraint(rule = Flow_Nitrog)\n",
    "model.Tout_constr = pyo.Constraint(rule = Tout_bounds)\n",
    "model.Tout_M_constr = pyo.Constraint(rule = TOut_mem_bounds)\n",
    "model.Flow_DME = pyo.Constraint(rule = Flow_DME)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rule(m):\n",
    "    prices = {\n",
    "        \"MeOH\": 891*1e-6,  # Cost of Methanol in $/kg\n",
    "        \"DME\": 2021.84*1e-6,   # Cost of Dimethyl Ether in $/kg\n",
    "        \"H2O\": 0.29*1e-6,  # Cost of Water in $/kg\n",
    "        \"N2\": 121.254*1e-6  # Cost of Nitrogen in $/kg\n",
    "    }\n",
    "\n",
    "    MW = {\n",
    "        \"MeOH\": 32.04,  # MW of Methanol in g/mol\n",
    "        \"DME\": 46.069,   # Cost of Dimethyl Ether in $/kg\n",
    "        \"H2O\": 18.0152,  # Cost of Water in $/kg\n",
    "        \"N2\": 28.0134  # Cost of Nitrogen in $/kg\n",
    "    }\n",
    "\n",
    "    DME_O = m.membrane.outputs[outputs.index(\"F_DME_O\")]*y_factor[outputs.index(\"F_DME_O\")]\n",
    "    H2O_O = m.membrane.outputs[outputs.index(\"F_H2O_O\")]*y_factor[outputs.index(\"F_H2O_O\")]\n",
    "    H2O_M_O = m.membrane.outputs[outputs.index(\"F_H2O_M_O\")]*y_factor[outputs.index(\"F_H2O_M_O\")]\n",
    "    MeOH_In = m.membrane.inputs[inputs.index(\"F_MeOH\")]*x_factor[inputs.index(\"F_MeOH\")]\n",
    "    N2_In = m.membrane.inputs[inputs.index(\"F_N2\")]*x_factor[inputs.index(\"F_N2\")]\n",
    "    DME_In = m.membrane.inputs[inputs.index(\"F_DME\")]*x_factor[inputs.index(\"F_DME\")]\n",
    "\n",
    "    product_profit = prices[\"DME\"]*DME_O * MW[\"DME\"] + prices[\"H2O\"]*(H2O_O + H2O_M_O) * MW[\"H2O\"]\n",
    "\n",
    "    feedstock_cost = prices[\"MeOH\"]*MeOH_In * MW[\"MeOH\"] + prices[\"N2\"]*N2_In * MW[\"N2\"] + prices[\"DME\"]*DME_O * MW[\"DME\"]\n",
    "    return product_profit - feedstock_cost\n",
    "\n",
    "model.objective = pyo.Objective(rule = objective_rule, sense = pyo.maximize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipopt 3.14.6: \n",
      "==> Warning: Treating 64 binary and 0 integer variables as continuous.\n",
      "\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.14.6, running with linear solver MUMPS 5.2.1.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:     1526\n",
      "Number of nonzeros in inequality constraint Jacobian.:      514\n",
      "Number of nonzeros in Lagrangian Hessian.............:       45\n",
      "\n",
      "Total number of variables............................:      241\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:      225\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:      111\n",
      "Total number of inequality constraints...............:      263\n",
      "        inequality constraints with only lower bounds:       64\n",
      "   inequality constraints with lower and upper bounds:        7\n",
      "        inequality constraints with only upper bounds:      192\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  5.2358346e-02 4.60e+02 7.76e-01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  5.2301469e-02 4.60e+02 8.46e-01  -1.0 6.42e+00    -  6.72e-03 1.00e-03f  1\n",
      "   2  5.1871455e-02 4.53e+02 8.34e-01  -1.0 1.57e+00    -  1.44e-02 1.44e-02f  1\n",
      "   3  5.2283139e-02 4.38e+02 7.99e-01  -1.0 5.09e+00    -  2.86e-02 3.14e-02f  1\n",
      "   4  5.2454443e-02 4.08e+02 1.12e+00  -1.0 7.69e+00    -  5.13e-02 6.80e-02f  1\n",
      "   5  5.2638039e-02 3.59e+02 1.16e+00  -1.0 1.14e+01    -  1.06e-01 1.14e-01f  1\n",
      "   6  5.3589522e-02 1.76e+02 7.40e+00  -1.0 1.16e+01    -  1.55e-01 4.94e-01f  1\n",
      "   7  5.3506319e-02 1.74e+02 8.31e+01  -1.0 6.84e+00    -  5.78e-01 1.05e-02h  1\n",
      "   8  5.3610859e-02 1.71e+02 2.05e+03  -1.0 6.06e+01    -  2.80e-01 1.30e-02h  1\n",
      "   9  5.3612204e-02 1.71e+02 4.74e+06  -1.0 5.49e+01    -  3.18e-01 1.43e-04h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10r 5.3612204e-02 1.71e+02 1.00e+03   1.8 0.00e+00    -  0.00e+00 4.26e-07R  3\n",
      "  11r 9.7439298e-02 1.06e+02 1.00e+03   1.8 1.62e+04    -  7.38e-04 2.01e-03f  1\n",
      "  12r 1.1690202e-01 1.06e+02 1.27e+04   1.8 1.90e+03    -  1.23e-01 3.06e-03f  1\n",
      "  13r 2.3542590e-01 1.06e+02 2.42e+04   1.8 2.70e+02    -  2.78e-01 1.26e-01f  1\n",
      "  14r 2.6149890e-01 1.06e+02 3.56e+04   1.8 1.40e+01    -  8.42e-01 4.73e-01f  1\n",
      "  15r 2.6866389e-01 1.06e+02 8.01e+01   1.8 2.86e+00    -  9.92e-01 1.00e+00f  1\n",
      "  16r 2.5229405e-01 1.06e+02 2.01e+01  -0.3 7.61e+00    -  7.19e-01 6.92e-01f  1\n",
      "  17r 2.4059086e-01 1.06e+02 6.41e+01  -0.3 4.11e+00    -  7.37e-01 5.74e-01f  1\n",
      "  18r 2.2967887e-01 1.06e+02 7.97e+01  -0.3 8.57e-01    -  7.76e-01 5.94e-01f  1\n",
      "  19r 2.2237206e-01 1.06e+02 6.32e+01  -0.3 2.47e+00    -  9.61e-01 7.66e-01f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  20r 2.1287583e-01 1.06e+02 4.81e-06  -0.3 3.98e+00    -  1.00e+00 1.00e+00f  1\n",
      "  21r 2.0426832e-01 1.06e+02 4.53e+01  -2.6 5.93e+00    -  8.24e-01 6.57e-01f  1\n",
      "  22r 2.0033106e-01 1.06e+02 2.66e+01  -2.6 1.89e+00    -  9.07e-01 1.00e+00f  1\n",
      "  23r 1.8574781e-01 1.06e+02 2.67e-08  -2.6 8.52e+00    -  1.00e+00 1.00e+00f  1\n",
      "  24r 1.5706173e-01 1.06e+02 1.34e+00  -5.8 1.37e+01    -  5.56e-01 9.98e-01f  1\n",
      "  25r 1.5690775e-01 1.06e+02 1.37e+01  -5.8 2.41e-01    -  9.84e-01 8.95e-01f  1\n",
      "  26r 1.4162707e-01 1.06e+02 2.88e+02  -5.8 4.27e+00    -  4.34e-01 1.00e+00f  1\n",
      "  27r 1.3088267e-01 1.06e+02 7.82e+00  -5.8 4.63e+00    -  9.42e-01 1.00e+00f  1\n",
      "  28r 1.2377980e-01 1.06e+02 1.64e-11  -5.8 2.66e+00    -  1.00e+00 1.00e+00f  1\n",
      "  29r 1.2124194e-01 1.06e+02 1.19e+01  -8.7 1.93e+00    -  8.10e-01 7.59e-01f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  30r 1.2177941e-01 1.06e+02 9.84e-01  -8.7 8.46e-02    -  9.63e-01 9.58e-01f  1\n",
      "  31r 1.2177169e-01 1.06e+02 7.30e-01  -8.7 4.51e-01    -  1.00e+00 4.47e-01f  1\n",
      "\n",
      "Number of Iterations....: 31\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   1.2112017708996195e-01    1.2112017708996195e-01\n",
      "Dual infeasibility......:   1.0903172121476308e+00    1.0903172121476308e+00\n",
      "Constraint violation....:   6.0176930303473554e+01    1.0637672670077102e+02\n",
      "Variable bound violation:   9.9999790670324273e-09    9.9999790670324273e-09\n",
      "Complementarity.........:   6.5142676507538037e-09    6.5142676507538037e-09\n",
      "Overall NLP error.......:   6.0176930303473554e+01    1.0637672670077102e+02\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 36\n",
      "Number of objective gradient evaluations             = 12\n",
      "Number of equality constraint evaluations            = 36\n",
      "Number of inequality constraint evaluations          = 36\n",
      "Number of equality constraint Jacobian evaluations   = 34\n",
      "Number of inequality constraint Jacobian evaluations = 34\n",
      "Number of Lagrangian Hessian evaluations             = 32\n",
      "Total seconds in IPOPT                               = 0.085\n",
      "\n",
      "EXIT: Converged to a point of local infeasibility. Problem may be infeasible.\n",
      "WARNING: Loading a SolverResults object with a warning status into\n",
      "model.name=\"unknown\";\n",
      "    - termination condition: infeasible\n",
      "    - message from solver: Ipopt 3.14.6\\x3a Converged to a locally infeasible\n",
      "      point. Problem may be infeasible.\n"
     ]
    }
   ],
   "source": [
    "solver = pyo.SolverFactory(\"ipopt\")\n",
    "status = solver.solve(model, tee=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMEOH: 1.4635839387604128\n",
      "FDME: 3.53933570429962\n",
      "FDME: 3.053394814317036\n",
      "FH2O: 2.768737599557221\n",
      "FH2OM: 3.5563714603307437\n",
      "FN2: 10.041639063780295\n",
      "FN2O: 10.041639063780295\n",
      "Tout: 691.1287698454883\n",
      "F_MEOH_O: 1.0906626435647984\n",
      "5.223506068219308e-05\n"
     ]
    }
   ],
   "source": [
    "F_MEOH_IN = pyo.value(model.membrane.inputs[inputs.index(\"F_MeOH\")])*x_factor[inputs.index(\"F_MeOH\")]\n",
    "F_MEOH_OUT = pyo.value(model.membrane.outputs[outputs.index(\"F_MeOH_O\")])*y_factor[outputs.index(\"F_MeOH_O\")]\n",
    "CONVERSION = (F_MEOH_IN - F_MEOH_OUT)/F_MEOH_IN\n",
    "\n",
    "print(\"FMEOH:\", F_MEOH_IN)\n",
    "print(\"FDME:\", pyo.value(model.membrane.inputs[inputs.index(\"F_DME\")])*x_factor[inputs.index(\"F_DME\")])\n",
    "print(\"FDME:\", pyo.value(model.membrane.outputs[outputs.index(\"F_DME_O\")])*y_factor[outputs.index(\"F_DME_O\")])\n",
    "print(\"FH2O:\", pyo.value(model.membrane.outputs[outputs.index(\"F_H2O_O\")])*y_factor[outputs.index(\"F_H2O_O\")])\n",
    "print(\"FH2OM:\", pyo.value(model.membrane.outputs[outputs.index(\"F_H2O_M_O\")])*y_factor[outputs.index(\"F_H2O_M_O\")])\n",
    "print(\"FN2:\", pyo.value(model.membrane.inputs[inputs.index(\"F_N2\")])*x_factor[inputs.index(\"F_N2\")])\n",
    "print(\"FN2O:\", pyo.value(model.membrane.outputs[outputs.index(\"F_N2_O\")])*y_factor[outputs.index(\"F_N2_O\")])\n",
    "print(\"Tout:\", pyo.value(model.membrane.outputs[outputs.index(\"T_Out\")])*y_factor[outputs.index(\"T_Out\")])\n",
    "print(\"F_MEOH_O:\", F_MEOH_OUT)\n",
    "print(\"Conversion:\", CONVERSION)\n",
    "print(pyo.value(model.MassBal))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_factor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemfigmkr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
