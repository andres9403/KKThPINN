{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 11:11:43.669761: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-12 11:11:43.847760: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736701903.914959    5138 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736701903.934900    5138 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-12 11:11:44.096298: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from main import main\n",
    "from utils import LoadData, LoadModel, load_data\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import pandas as pd\n",
    "# pyomo for optimization\n",
    "import pyomo.environ as pyo\n",
    "\n",
    "# pytorch for training neural network\n",
    "import torch.onnx\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# omlt for interfacing our neural network with pyomo\n",
    "import onnx\n",
    "from omlt import OffsetScaling, OmltBlock\n",
    "from omlt.io.onnx import (\n",
    "    load_onnx_neural_network_with_bounds,\n",
    "    write_onnx_model_with_bounds,\n",
    "    load_onnx_neural_network,\n",
    ")\n",
    "from omlt.neuralnet import (FullSpaceNNFormulation, \n",
    "    ReluComplementarityFormulation, \n",
    "    ReluPartitionFormulation,\n",
    "    ReducedSpaceNNFormulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_arguments(model,model_id,system,scenario):    \n",
    "    if system == 'membrane':\n",
    "        args = argparse.Namespace(\n",
    "            input_dim=7,\n",
    "            hidden_dim=32,\n",
    "            hidden_num=2,\n",
    "            z0_dim=8,\n",
    "            optimizer='adam',\n",
    "            epochs=1000,\n",
    "            batch_size=16,\n",
    "            lr=1e-4,\n",
    "            mu=1,\n",
    "            max_subiter=500,\n",
    "            eta=0.8,\n",
    "            sigma=2,\n",
    "            mu_safe=1e+9,\n",
    "            dtype=32,\n",
    "            dataset_path='/home/andresfel9403/KKThNN/KKThPINN/benchmark_membrane.csv',\n",
    "            val_ratio=0.2,\n",
    "            job='train',\n",
    "            runs=10)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    args.model = model\n",
    "    args.model_id = model_id\n",
    "    args.dataset_type = system\n",
    "    args.scenario = scenario\n",
    "        \n",
    "    \n",
    "    if args.model == 'NN':\n",
    "        args.loss_type = 'MSE'\n",
    "    elif args.model == 'PINN':\n",
    "        args.loss_type = 'PINN'\n",
    "    elif args.model == 'KKThPINN':\n",
    "        args.loss_type = 'MSE'\n",
    "    elif args.model == 'AugLagNN':\n",
    "        args.loss_type = 'MSE'\n",
    "    elif args.model == 'ECNN':\n",
    "        args.loss_type = 'MSE'\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['F_MeOH',\n",
    "    'F_DME',\n",
    "    'F_H2O',\n",
    "    'F_N2',\n",
    "    'T_in',\n",
    "    'P_in',\n",
    "    'T_permeate']\n",
    "\n",
    "outputs = [\n",
    "    'F_MeOH_O',\n",
    "    'F_DME_O',\n",
    "    'F_H2O_O',\n",
    "    'F_H2O_M_O',\n",
    "    'F_N2_O',\n",
    "    'T_Out',\n",
    "    'T_Out_M',\n",
    "    'P_Out'\n",
    "]\n",
    "\n",
    "columns = inputs+outputs\n",
    "\n",
    "df = pd.read_csv(\"benchmark_membrane.csv\", usecols = columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_NN = add_arguments('NN','MembraneT_NN','membrane','demonstration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of A: torch.float32, type of B: torch.float32, type of b: torch.float32\n",
      "train set size: 614, val set size: 204, test set size: 204\n",
      "Start Training...\n",
      "epoch: 00050 loss_train: 0.01253 loss_val: 0.01299 violation_train: 10.24131 violation_val: 10.80998\n",
      "epoch: 00100 loss_train: 0.00271 loss_val: 0.00300 violation_train: 2.26623 violation_val: 2.07504\n",
      "epoch: 00150 loss_train: 0.00105 loss_val: 0.00152 violation_train: 0.25400 violation_val: 0.28112\n",
      "epoch: 00200 loss_train: 0.00083 loss_val: 0.00130 violation_train: 0.25836 violation_val: 0.32832\n",
      "epoch: 00250 loss_train: 0.00072 loss_val: 0.00115 violation_train: 0.18442 violation_val: 0.21387\n",
      "epoch: 00300 loss_train: 0.00066 loss_val: 0.00106 violation_train: 0.18189 violation_val: 0.18695\n",
      "epoch: 00350 loss_train: 0.00065 loss_val: 0.00101 violation_train: 0.18037 violation_val: 0.20561\n",
      "epoch: 00400 loss_train: 0.00064 loss_val: 0.00100 violation_train: 0.22044 violation_val: 0.32950\n",
      "epoch: 00450 loss_train: 0.00063 loss_val: 0.00100 violation_train: 0.18537 violation_val: 0.22445\n",
      "epoch: 00500 loss_train: 0.00064 loss_val: 0.00101 violation_train: 0.20094 violation_val: 0.23834\n",
      "epoch: 00550 loss_train: 0.00063 loss_val: 0.00099 violation_train: 0.21665 violation_val: 0.24285\n",
      "epoch: 00600 loss_train: 0.00064 loss_val: 0.00100 violation_train: 0.21286 violation_val: 0.21989\n",
      "epoch: 00650 loss_train: 0.00065 loss_val: 0.00101 violation_train: 0.21341 violation_val: 0.22945\n",
      "epoch: 00700 loss_train: 0.00063 loss_val: 0.00101 violation_train: 0.22421 violation_val: 0.23454\n",
      "epoch: 00750 loss_train: 0.00063 loss_val: 0.00102 violation_train: 0.23587 violation_val: 0.25748\n",
      "epoch: 00800 loss_train: 0.00069 loss_val: 0.00098 violation_train: 0.23428 violation_val: 0.24556\n",
      "epoch: 00850 loss_train: 0.00062 loss_val: 0.00100 violation_train: 0.22177 violation_val: 0.24181\n",
      "epoch: 00900 loss_train: 0.00062 loss_val: 0.00097 violation_train: 0.21363 violation_val: 0.23855\n",
      "epoch: 00950 loss_train: 0.00062 loss_val: 0.00099 violation_train: 0.23829 violation_val: 0.28070\n",
      "epoch: 01000 loss_train: 0.00062 loss_val: 0.00105 violation_train: 0.24838 violation_val: 0.25154\n",
      "Finished!\n",
      "{'rmse_total': np.float64(0.028509869502780914), 'rmse_unconstrained': np.float64(0.007566930161183418), 'rmse_constrained': np.float64(0.009980778641945114), 'violation': 0.24028685688972473, 'post_rmse_total': np.float64(0.028313860491098373), 'post_rmse_unconstrained': np.float64(0.00534929405840119), 'post_rmse_constrained': np.float64(0.006221112784670691)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andresfel9403/KKThNN/KKThPINN/train.py:264: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(PATH)\n"
     ]
    }
   ],
   "source": [
    "main(args_NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the arguments depending on the number of inputs, hidden and output layers, we can train the model selecting the Neural Network model (NN or KKThPINN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of A: torch.float32, type of B: torch.float32, type of b: torch.float32\n",
      "train set size: 614, val set size: 204, test set size: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5138/2941437368.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(PATH)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, scaling = load_data(args_NN.dataset_path)\n",
    "inputs = dataset[:,:7]\n",
    "outputs = dataset[:,7:]\n",
    "\n",
    "data = LoadData(args_NN)\n",
    "model_NN = LoadModel(args_NN, data)\n",
    "PATH = '/home/andresfel9403/KKThNN/models/membrane/NN/0.2/None_0.2_9.pth'\n",
    "checkpoint = torch.load(PATH)\n",
    "model_NN.load_state_dict(checkpoint['state_dict'])\n",
    "#model_NN.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.46831994e+01 1.04111445e+01 1.42231966e+01 9.99584502e+01\n",
      " 7.26638589e+02 2.69926289e+06 1.76773269e+02]\n"
     ]
    }
   ],
   "source": [
    "x_factor = scaling.scale_[:7]\n",
    "y_factor = scaling.scale_[7:]\n",
    "\n",
    "print(x_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = scaler = OffsetScaling(\n",
    "    offset_inputs={i: 0 for i in range(len(x_factor))},\n",
    "    factor_inputs={i: x_factor[i] for i in range(len(x_factor))},\n",
    "    offset_outputs={i: 0 for i in range(len(y_factor))},\n",
    "    factor_outputs={i: y_factor[i] for i in range(len(y_factor))},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "x_dummy = torch.from_numpy(inputs[0]).float()\n",
    "ub = np.max(inputs, 0)\n",
    "lb = np.min(inputs, 0)\n",
    "\n",
    "scaled_input_bounds = {i: (lb[i], ub[i]) for i in range(len(inputs[0]))}\n",
    "print(ub.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_weights(original_model, modified_model):\n",
    "    with torch.no_grad():\n",
    "        for original_layer, modified_layer in zip(original_model.layers, modified_model.layers):\n",
    "            if isinstance(original_layer, nn.Linear) and isinstance(modified_layer, nn.Linear):\n",
    "                modified_layer.weight.copy_(original_layer.weight)\n",
    "                modified_layer.bias.copy_(original_layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_onnx_model(data,args,model,file_path,x,input_bounds):\n",
    "    args.model='NN'\n",
    "    print('Saving standard model')\n",
    "    modified_model = LoadModel(args,data)\n",
    "    transfer_weights(model,modified_model)\n",
    "    create_onnx_model(data,modified_model,file_path,x,input_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_onnx_model(data,model,file_path,x,input_bounds):\n",
    "    \n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        x,\n",
    "        file_path,\n",
    "        input_names=[\"input\"],\n",
    "        dynamo = False\n",
    "    )\n",
    "    write_onnx_model_with_bounds(file_path, None, input_bounds)\n",
    "    print(f\"Wrote PyTorch Onnx model to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving standard model\n",
      "Wrote PyTorch Onnx model to NN_Membrane.onnx\n"
     ]
    }
   ],
   "source": [
    "_create_onnx_model(data,args_NN,model_NN,'NN_Membrane.onnx',x_dummy,scaled_input_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tempfile.NamedTemporaryFile(suffix=\".onnx\", delete=False) as f:\n",
    "    # export neural network to ONNX\n",
    "torch.onnx.export(\n",
    "    model_NN,\n",
    "    x_dummy,\n",
    "    'intento.onnx',\n",
    "    input_names=[\"input\"],\n",
    "    dynamo = False\n",
    ")\n",
    "# write ONNX model and its bounds using OMLT\n",
    "write_onnx_model_with_bounds('intento.onnx', None, scaled_input_bounds)\n",
    "onnx_model = onnx.load('intento.onnx')\n",
    "# load the network definition from the ONNX model\n",
    "#network_definition = load_onnx_neural_network_with_bounds('intento.onnx')\n",
    "network_definition = load_onnx_neural_network(onnx = onnx_model,  scaling_object=scaler, input_bounds= scaled_input_bounds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_definition_NN = load_onnx_neural_network_with_bounds('NN_Membrane.onnx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "formulation_NN = FullSpaceNNFormulation(network_definition_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tInputLayer(input_size=[7], output_size=[7])\tlinear\n",
      "1\tDenseLayer(input_size=[7], output_size=[32])\trelu\n",
      "2\tDenseLayer(input_size=[32], output_size=[32])\trelu\n",
      "3\tDenseLayer(input_size=[32], output_size=[8])\tlinear\n"
     ]
    }
   ],
   "source": [
    "for layer_id, layer in enumerate(network_definition_NN.layers):\n",
    "    print(f\"{layer_id}\\t{layer}\\t{layer.activation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[0]' to a numeric value\n",
      "`0` outside the bounds (0.002303625455624813, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[0]' to a numeric value\n",
      "`0` outside the bounds (0.002303625455624813, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[1]' to a numeric value\n",
      "`0` outside the bounds (0.00045880834803283796, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[2]' to a numeric value\n",
      "`0` outside the bounds (0.0022512226291679363, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[3]' to a numeric value\n",
      "`0` outside the bounds (0.10018982303101381, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[4]' to a numeric value\n",
      "`0` outside the bounds (0.25788606628182886, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[5]' to a numeric value\n",
      "`0` outside the bounds (0.4816711270961038, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'membrane.scaled_inputs[6]' to a numeric value\n",
      "`0` outside the bounds (0.056910004685567034, 1.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n"
     ]
    }
   ],
   "source": [
    "model = pyo.ConcreteModel()\n",
    "\n",
    "# create an OMLT block for the neural network and build its formulation\n",
    "model.membrane= OmltBlock()\n",
    "model.membrane.build_formulation(formulation_NN)\n",
    "\n",
    "# model.sections = pyo.Set(initialize=[\"retentate\", \"permeate\"], doc=\"sections in the model\")\n",
    "# model.components = pyo.Set(initialize=[\"MeOH\", \"DME\", \"H2O\", \"N2\"], doc=\"Components in the model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Implicitly replacing the Component attribute Tin_constr (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute Tm_constr (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute TFlow_constr\n",
      "(type=<class 'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown\n",
      "with a new Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "WARNING: Implicitly replacing the Component attribute P_constr (type=<class\n",
      "'pyomo.core.base.constraint.ScalarConstraint'>) on block unknown with a new\n",
      "Component (type=<class\n",
      "'pyomo.core.base.constraint.AbstractScalarConstraint'>). This is usually\n",
      "indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n"
     ]
    }
   ],
   "source": [
    "inputs = ['F_MeOH',\n",
    "    'F_DME',\n",
    "    'F_H2O',\n",
    "    'F_N2',\n",
    "    'T_in',\n",
    "    'P_in',\n",
    "    'T_permeate']\n",
    "\n",
    "outputs = [\n",
    "    'F_MeOH_O',\n",
    "    'F_DME_O',\n",
    "    'F_H2O_O',\n",
    "    'F_H2O_M_O',\n",
    "    'F_N2_O',\n",
    "    'T_Out',\n",
    "    'T_Out_M',\n",
    "    'P_Out'\n",
    "]\n",
    "\n",
    "Tin_idx = inputs.index('T_in')\n",
    "Tm_idx = inputs.index('T_permeate')\n",
    "F_MeOH_idx = inputs.index('F_MeOH')\n",
    "F_DME_idx = inputs.index('F_DME')\n",
    "F_H2O_idx = inputs.index('F_H2O')\n",
    "F_N2_idx = inputs.index('F_N2')\n",
    "P_in_idx = inputs.index('P_in')\n",
    "\n",
    "def Tin_bounds(m):\n",
    "    return (460/x_factor[Tin_idx],m.membrane.inputs[Tin_idx],1000/x_factor[Tin_idx])\n",
    "\n",
    "def T_mem_bounds(m):\n",
    "    return (283.15/x_factor[Tm_idx],m.membrane.inputs[Tm_idx],450/x_factor[Tm_idx])\n",
    "\n",
    "def TFlow_bounds(m):\n",
    "    FMeOh = m.membrane.inputs[F_MeOH_idx]*x_factor[F_MeOH_idx]\n",
    "    FDME = m.membrane.inputs[F_DME_idx]*x_factor[F_DME_idx]\n",
    "    FH2O = m.membrane.inputs[F_H2O_idx]*x_factor[F_H2O_idx]\n",
    "    FN2 = m.membrane.inputs[F_N2_idx]*x_factor[F_N2_idx]\n",
    "    Ftot = FMeOh + FDME + FH2O + FN2\n",
    "    return (1, Ftot, 100)\n",
    "\n",
    "def Flow_DME(m):\n",
    "\n",
    "    return (0, m.membrane.inputs[F_DME_idx], 0.005)\n",
    "\n",
    "def P_bounds(m):\n",
    "    return (13e5/x_factor[P_in_idx], m.membrane.inputs[P_in_idx], 27e5)\n",
    "\n",
    "model.Tin_constr = pyo.Constraint(rule = Tin_bounds)\n",
    "model.Tm_constr = pyo.Constraint(rule = T_mem_bounds)\n",
    "model.TFlow_constr = pyo.Constraint(rule = TFlow_bounds)\n",
    "model.P_constr = pyo.Constraint(rule = P_bounds)\n",
    "#model.Flow_DME = pyo.Constraint(rule = Flow_DME)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "DME_O = model.membrane.outputs[outputs.index(\"F_DME_O\")]*y_factor[outputs.index(\"F_DME_O\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Implicitly replacing the Component attribute objective (type=<class\n",
      "'pyomo.core.base.objective.ScalarObjective'>) on block unknown with a new\n",
      "Component (type=<class 'pyomo.core.base.objective.ScalarObjective'>). This is\n",
      "usually indicative of a modelling error. To avoid this warning, use\n",
      "block.del_component() and block.add_component().\n",
      "ERROR: Rule failed when generating expression for Objective objective with\n",
      "index None: KeyError: 'H20'\n",
      "ERROR: Constructing component 'objective' from data=None failed:\n",
      "        KeyError: 'H20'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'H20'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     feedstock_cost \u001b[38;5;241m=\u001b[39m prices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeOH\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39mMeOH_In\u001b[38;5;241m*\u001b[39mMW[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeOH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m prices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39mN2_In\u001b[38;5;241m*\u001b[39mMW[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m prices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDME\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39mDME_In\u001b[38;5;241m*\u001b[39mMW[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDME\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m product_profit \u001b[38;5;241m-\u001b[39m feedstock_cost\n\u001b[0;32m---> 28\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective\u001b[49m \u001b[38;5;241m=\u001b[39m pyo\u001b[38;5;241m.\u001b[39mObjective(rule \u001b[38;5;241m=\u001b[39m objective_rule, sense \u001b[38;5;241m=\u001b[39m pyo\u001b[38;5;241m.\u001b[39mmaximize)\n",
      "File \u001b[0;32m~/anaconda3/envs/chemfigmkr/lib/python3.12/site-packages/pyomo/core/base/block.py:601\u001b[0m, in \u001b[0;36mBlockData.__setattr__\u001b[0;34m(self, name, val)\u001b[0m\n\u001b[1;32m    592\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    593\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplicitly replacing the Component attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    594\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (type=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) on block \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m with a new Component (type=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[38;5;241m%\u001b[39m (name, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent(name)), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mtype\u001b[39m(val))\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdel_component(name)\n\u001b[0;32m--> 601\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_component\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;66;03m# The incoming value is not a component, so we set the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;66;03m# generated while setting the value.\u001b[39;00m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/chemfigmkr/lib/python3.12/site-packages/pyomo/core/base/block.py:1105\u001b[0m, in \u001b[0;36mBlockData.add_component\u001b[0;34m(self, name, val)\u001b[0m\n\u001b[1;32m   1097\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1098\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstructing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m from data=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1099\u001b[0m         val\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;28mstr\u001b[39m(data),\n\u001b[1;32m   1103\u001b[0m     )\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1105\u001b[0m     \u001b[43mval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1107\u001b[0m     err \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/chemfigmkr/lib/python3.12/site-packages/pyomo/core/base/objective.py:335\u001b[0m, in \u001b[0;36mObjective.construct\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# Bypass the index validation and create the member directly\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_set():\n\u001b[0;32m--> 335\u001b[0m     ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_when_not_present(index, \u001b[43mrule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ans \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    337\u001b[0m         ans\u001b[38;5;241m.\u001b[39mset_sense(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_sense(block, index))\n",
      "File \u001b[0;32m~/anaconda3/envs/chemfigmkr/lib/python3.12/site-packages/pyomo/core/base/initializer.py:483\u001b[0m, in \u001b[0;36mScalarCallInitializer.__call__\u001b[0;34m(self, parent, idx)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, parent, idx):\n\u001b[0;32m--> 483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[95], line 23\u001b[0m, in \u001b[0;36mobjective_rule\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     20\u001b[0m N2_In \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mmembrane\u001b[38;5;241m.\u001b[39minputs[inputs\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF_N2\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\u001b[38;5;241m*\u001b[39mx_factor[inputs\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF_N2\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     21\u001b[0m DME_In \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mmembrane\u001b[38;5;241m.\u001b[39minputs[inputs\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF_DME\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\u001b[38;5;241m*\u001b[39mx_factor[inputs\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF_DME\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m---> 23\u001b[0m product_profit \u001b[38;5;241m=\u001b[39m prices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDME\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39mDME_O\u001b[38;5;241m*\u001b[39mMW[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDME\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m prices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH2O\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39mH2O_O\u001b[38;5;241m*\u001b[39m\u001b[43mMW\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mH20\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m prices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH2O\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39mH2O_M_O\u001b[38;5;241m*\u001b[39mMW[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH20\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     25\u001b[0m feedstock_cost \u001b[38;5;241m=\u001b[39m prices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeOH\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39mMeOH_In\u001b[38;5;241m*\u001b[39mMW[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeOH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m prices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39mN2_In\u001b[38;5;241m*\u001b[39mMW[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m prices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDME\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39mDME_In\u001b[38;5;241m*\u001b[39mMW[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDME\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m product_profit \u001b[38;5;241m-\u001b[39m feedstock_cost\n",
      "\u001b[0;31mKeyError\u001b[0m: 'H20'"
     ]
    }
   ],
   "source": [
    "def objective_rule(m):\n",
    "    prices = {\n",
    "        \"MeOH\": 891*1e-6,  # Cost of Methanol in $/kg\n",
    "        \"DME\": 2021.84*1e-6,   # Cost of Dimethyl Ether in $/kg\n",
    "        \"H2O\": 0.29*1e-6,  # Cost of Water in $/kg\n",
    "        \"N2\": 121.254*1e-6  # Cost of Nitrogen in $/kg\n",
    "    }\n",
    "\n",
    "    MW = {\n",
    "        \"MeOH\": 32.04,  # MW of Methanol in g/mol\n",
    "        \"DME\": 46.069,   # Cost of Dimethyl Ether in $/kg\n",
    "        \"H2O\": 18.0152,  # Cost of Water in $/kg\n",
    "        \"N2\": 28.0134  # Cost of Nitrogen in $/kg\n",
    "    }\n",
    "\n",
    "    DME_O = m.membrane.outputs[outputs.index(\"F_DME_O\")]*y_factor[outputs.index(\"F_DME_O\")]\n",
    "    H2O_O = m.membrane.outputs[outputs.index(\"F_H2O_O\")]*y_factor[outputs.index(\"F_H2O_O\")]\n",
    "    H2O_M_O = m.membrane.outputs[outputs.index(\"F_H2O_M_O\")]*y_factor[outputs.index(\"F_H2O_M_O\")]\n",
    "    MeOH_In = m.membrane.inputs[inputs.index(\"F_MeOH\")]*x_factor[inputs.index(\"F_MeOH\")]\n",
    "    N2_In = m.membrane.inputs[inputs.index(\"F_N2\")]*x_factor[inputs.index(\"F_N2\")]\n",
    "    DME_In = m.membrane.inputs[inputs.index(\"F_DME\")]*x_factor[inputs.index(\"F_DME\")]\n",
    "\n",
    "    product_profit = prices[\"DME\"]*DME_O*MW[\"DME\"] + prices[\"H2O\"]*H2O_O*MW[\"H20\"] + prices[\"H2O\"]*H2O_M_O*MW[\"H20\"]\n",
    "\n",
    "    feedstock_cost = prices[\"MeOH\"]*MeOH_In*MW[\"MeOH\"] + prices[\"N2\"]*N2_In*MW[\"N2\"] + prices[\"DME\"]*DME_In*MW[\"DME\"]\n",
    "    return product_profit - feedstock_cost\n",
    "\n",
    "model.objective = pyo.Objective(rule = objective_rule, sense = pyo.maximize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipopt 3.14.6: \n",
      "==> Warning: Treating 64 binary and 0 integer variables as continuous.\n",
      "\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.14.6, running with linear solver MUMPS 5.2.1.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:     1524\n",
      "Number of nonzeros in inequality constraint Jacobian.:      504\n",
      "Number of nonzeros in Lagrangian Hessian.............:        0\n",
      "\n",
      "Total number of variables............................:      241\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:      225\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:      110\n",
      "Total number of inequality constraints...............:      261\n",
      "        inequality constraints with only lower bounds:       64\n",
      "   inequality constraints with lower and upper bounds:        5\n",
      "        inequality constraints with only upper bounds:      192\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0 -5.1270513e-03 6.11e-01 7.52e-01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1 -5.1662297e-03 6.09e-01 4.12e+01  -1.0 1.69e+00    -  6.34e-01 1.78e-02f  1\n",
      "   2 -5.1684035e-03 6.02e-01 1.78e+03  -1.0 4.73e+00    -  5.55e-01 1.26e-02h  1\n",
      "   3 -5.1685145e-03 6.02e-01 2.45e+06  -1.0 7.76e+00    -  2.46e-01 1.81e-04h  1\n",
      "   4r-5.1685145e-03 6.02e-01 1.00e+03  -0.2 0.00e+00    -  0.00e+00 2.50e-07R  4\n",
      "   5r-5.3562140e-03 6.02e-01 9.31e+02  -0.2 4.28e+01    -  2.73e-01 6.91e-02f  1\n",
      "   6r-4.3832976e-03 6.02e-01 6.09e+02  -0.2 3.13e+01    -  4.12e-01 3.46e-01f  1\n",
      "   7r-6.7707024e-04 6.03e-01 3.90e+00  -0.2 2.73e+01    -  9.90e-01 1.00e+00f  1\n",
      "   8r-7.9929474e-04 6.03e-01 8.18e-01  -0.2 2.42e+00    -  9.90e-01 1.00e+00f  1\n",
      "   9r-1.3905713e-03 6.02e-01 3.86e+01  -0.9 3.87e+00    -  9.98e-01 8.29e-01f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10r-1.6700291e-03 6.02e-01 1.20e-06  -0.9 1.79e+00    -  1.00e+00 1.00e+00f  1\n",
      "  11r-2.7955655e-03 6.02e-01 1.03e+01  -3.6 7.57e+00    -  7.98e-01 9.06e-01f  1\n",
      "  12r-2.9457963e-03 6.02e-01 3.61e-01  -3.6 9.43e-01    -  9.82e-01 1.00e+00f  1\n",
      "  13r-4.1463061e-03 6.02e-01 2.28e-09  -3.6 1.08e+01    -  1.00e+00 1.00e+00f  1\n",
      "  14r-4.9530668e-03 6.02e-01 1.44e+00  -5.5 8.66e+00    -  7.02e-01 1.00e+00f  1\n",
      "  15r-5.0350896e-03 6.02e-01 4.73e+00  -5.5 7.82e-01    -  9.89e-01 1.00e+00f  1\n",
      "  16r-5.1714211e-03 6.02e-01 3.46e-11  -5.5 2.78e+00    -  1.00e+00 1.00e+00f  1\n",
      "  17r-5.2354684e-03 6.02e-01 4.14e+01  -8.2 1.97e+00    -  8.71e-01 6.99e-01f  1\n",
      "  18r-5.2520921e-03 6.02e-01 2.95e+01  -8.2 2.17e-01    -  9.32e-01 8.47e-01f  1\n",
      "  19r-5.2525453e-03 6.02e-01 1.68e+01  -8.2 6.52e-01    -  1.00e+00 4.06e-01f  1\n",
      "\n",
      "Number of Iterations....: 19\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:  -5.2557842229991950e-03   -5.2557842229991950e-03\n",
      "Dual infeasibility......:   2.3667158700145147e-02    2.3667158700145147e-02\n",
      "Constraint violation....:   6.0176930304821230e-01    6.0176930304821230e-01\n",
      "Variable bound violation:   9.9865020697365026e-09    9.9865020697365026e-09\n",
      "Complementarity.........:   1.4507981435155956e-08    1.4507981435155956e-08\n",
      "Overall NLP error.......:   6.0176930304821230e-01    6.0176930304821230e-01\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 25\n",
      "Number of objective gradient evaluations             = 6\n",
      "Number of equality constraint evaluations            = 25\n",
      "Number of inequality constraint evaluations          = 25\n",
      "Number of equality constraint Jacobian evaluations   = 22\n",
      "Number of inequality constraint Jacobian evaluations = 22\n",
      "Number of Lagrangian Hessian evaluations             = 20\n",
      "Total seconds in IPOPT                               = 0.058\n",
      "\n",
      "EXIT: Converged to a point of local infeasibility. Problem may be infeasible.\n",
      "WARNING: Loading a SolverResults object with a warning status into\n",
      "model.name=\"unknown\";\n",
      "    - termination condition: infeasible\n",
      "    - message from solver: Ipopt 3.14.6\\x3a Converged to a locally infeasible\n",
      "      point. Problem may be infeasible.\n"
     ]
    }
   ],
   "source": [
    "solver = pyo.SolverFactory(\"ipopt\")\n",
    "status = solver.solve(model, tee=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FA: 0.2991536256509395\n",
      "FDME: 0.043793769214874455\n",
      "FDME: 3.506323355784384\n",
      "FH2O: 1.7887266525660925\n",
      "FH2OM: 5.088371816962074\n",
      "FN2: 12.208628782651937\n",
      "Tout: 738.6718774395302\n",
      "14.40570949450101\n"
     ]
    }
   ],
   "source": [
    "print(\"FA:\", pyo.value(model.membrane.inputs[inputs.index(\"F_MeOH\")])*x_factor[inputs.index(\"F_MeOH\")])\n",
    "print(\"FDME:\", pyo.value(model.membrane.inputs[inputs.index(\"F_DME\")])*x_factor[inputs.index(\"F_DME\")])\n",
    "print(\"FDME:\", pyo.value(model.membrane.outputs[outputs.index(\"F_DME_O\")])*y_factor[outputs.index(\"F_DME_O\")])\n",
    "print(\"FH2O:\", pyo.value(model.membrane.outputs[outputs.index(\"F_H2O_O\")])*y_factor[outputs.index(\"F_H2O_O\")])\n",
    "print(\"FH2OM:\", pyo.value(model.membrane.outputs[outputs.index(\"F_H2O_M_O\")])*y_factor[outputs.index(\"F_H2O_M_O\")])\n",
    "print(\"FN2:\", pyo.value(model.membrane.inputs[inputs.index(\"F_N2\")])*x_factor[inputs.index(\"F_N2\")])\n",
    "print(\"Tout:\", pyo.value(model.membrane.outputs[outputs.index(\"T_Out\")])*y_factor[outputs.index(\"T_Out\")])\n",
    "print(pyo.value(model.TFlow_constr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_factor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemfigmkr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
